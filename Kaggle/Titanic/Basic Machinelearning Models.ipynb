{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Data Explorations notebook I explored the Titanic Data set and didsome feature extraction. Lets test some prediction models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do some machine learning to see what kind of accuracy we can achive playing around with the data we have so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regex_extract(s, regex, capture_group=1):\n",
    "    search = re.search(regex, s)\n",
    "    if search:\n",
    "        return search.group(capture_group)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework\n",
    "Before we start builiding models, lets set up a simple framework to test and evaluate them with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class Classifier(object):\n",
    "    \n",
    "    def predict(row):\n",
    "        return None\n",
    "\n",
    "# Extract the features I liked the most from the Data Exploration notebook\n",
    "def prepare_training_data(training_data):\n",
    "    data = training_data.copy()\n",
    "    data['Title'] = data['Name'].apply(lambda x: regex_extract(x, \".*\\,\\s(.*?)\\.\"))\n",
    "    data['Title'] = data['Title'].apply(lambda x: x if x in ['Mr', 'Mrs', 'Miss', 'Master'] else \"Other\")\n",
    "    data['Child'] = data['Age'].apply(lambda x: x < 18)\n",
    "    data['Child'] = data['Child'].fillna('Unknown')\n",
    "    \n",
    "    tickets = data.groupby(['Ticket']).agg({'Survived' : 'sum', 'PassengerId' : 'count'}).rename(columns={'Survived' : 'SurvivedInCompany','PassengerId' : 'CompanySize'}).reset_index()\n",
    "    data = data.merge(tickets, on = 'Ticket', how = 'left')\n",
    "    data['SurvivingCompanions'] = data.apply(lambda row: row['SurvivedInCompany'] - row['Survived'], axis=1)\n",
    "    data['DeadCompanions'] = data.apply(lambda row: row['CompanySize'] - row['SurvivedInCompany'] + row['Survived'], axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Extract features from the test set as well!\n",
    "def prepare_test_data(test_data, training_data):\n",
    "    data = test_data.copy()\n",
    "    data['Title'] = data['Name'].apply(lambda x: regex_extract(x, \".*\\,\\s(.*?)\\.\"))\n",
    "    data['Title'] = data['Title'].apply(lambda x: x if x in ['Mr', 'Mrs', 'Miss', 'Master'] else \"Other\")\n",
    "    data['Child'] = data['Age'].apply(lambda x: x < 18)\n",
    "    data['Child'] = data['Child'].fillna('Unknown')\n",
    "    \n",
    "    tickets = training_data.groupby(['Ticket']).agg({'Survived' : 'sum', 'PassengerId' : 'count'}).rename(columns={'Survived' : 'SurvivedInCompany','PassengerId' : 'CompanySize'}).reset_index()\n",
    "    data = data.merge(tickets, on = 'Ticket', how = 'left')\n",
    "    data['SurvivedInCompany'] = data['SurvivedInCompany'].fillna(0)\n",
    "    data['CompanySize'] = data['CompanySize'].fillna(0)\n",
    "    data['SurvivingCompanions'] = data.apply(lambda row: row['SurvivedInCompany'], axis=1)\n",
    "    data['DeadCompanions'] = data.apply(lambda row: row['CompanySize'] - row['SurvivedInCompany'], axis=1)\n",
    "    return data\n",
    "    \n",
    "def evaluate_model(model, test_data, target=\"Survived\", evaluate=False):\n",
    "    predictions = test_data.apply(model.predict, axis = 1)\n",
    "    if evaluate:\n",
    "        correct = n = 0.0\n",
    "        for ans, pred in zip(test_data[target], predictions):\n",
    "            n+= 1\n",
    "            if ans == pred:\n",
    "                correct += 1\n",
    "        print(\"Accuracy on {} samples: {}\".format(n, correct/n))\n",
    "        return\n",
    "    else:\n",
    "        return zip(test_data['PassengerId'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets prepare some training and test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a random test set with 25% of all values\n",
    "import random\n",
    "random.seed(1)\n",
    "train_index = []\n",
    "test_index = []\n",
    "for i in range(len(data)):\n",
    "    if random.random() > 0.75:\n",
    "        test_index.append(i)\n",
    "    else:\n",
    "        train_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = data.iloc[train_index]\n",
    "test_data = data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider all variables independant and calculate the probability of survival as the mean survival rate for the given variable. We then uses Bayes theorem to calculate P(survival | independant variables). \n",
    "\n",
    "I will disregard quantitative variables for now as they require more work (Normalization etc.). I will classify any variable with small number of distinct values as categorical. (And ignore variables with high number of distinct values such as First name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes(Classifier):\n",
    "    def __init__(self, survival_rate, input_variables, prob_dict):\n",
    "        self.survival_rate = survival_rate\n",
    "        self.input_variables = input_variables\n",
    "        self.prob_dict = prob_dict\n",
    "    \n",
    "    def predict(self, row):\n",
    "        prob_survival = np.log(self.survival_rate)\n",
    "        prob_dead = np.log(1-self.survival_rate)\n",
    "        for variable in self.input_variables:\n",
    "            try:\n",
    "                prob_survival += np.log(self.prob_dict[variable][row[variable]])\n",
    "                prob_dead += np.log(1 - self.prob_dict[variable][row[variable]])\n",
    "            except(KeyError):\n",
    "                pass\n",
    "        return 1 if prob_survival > prob_dead else 0\n",
    "\n",
    "    @classmethod\n",
    "    def train(cls, data, categorical_variables, target, k=1):\n",
    "        prob_dict = {}\n",
    "        for variable in categorical_variables:\n",
    "            prob_dict[variable] = {}\n",
    "            for distinct_value in data[variable].unique():\n",
    "                df = data[data[variable] == distinct_value]\n",
    "                prob_dict[variable][distinct_value] = (df[target].sum() + k) / (df[target].count() + 2 * k)\n",
    "        return cls(data[target].mean(), categorical_variables, prob_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_training = prepare_training_data(training_data)\n",
    "naive_test = prepare_test_data(test_data, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_variables = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', 'Child', 'SurvivingCompanions', 'DeadCompanions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_bayes_companion_features = NaiveBayes.train(naive_training, categorical_variables, \"Survived\")\n",
    "naive_bayes_base = NaiveBayes.train(naive_training,  ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', 'Child'], \"Survived\")\n",
    "naive_bayes_two_features = NaiveBayes.train(naive_training, ['Pclass', 'Sex'], \"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With companion features:\n",
      "Accuracy on 233.0 samples: 0.703862660944206\n",
      "Without companions features:\n",
      "Accuracy on 233.0 samples: 0.7124463519313304\n",
      "Only Pclass and Sex:\n",
      "Accuracy on 233.0 samples: 0.7639484978540773\n"
     ]
    }
   ],
   "source": [
    "print(\"With companion features:\")\n",
    "evaluate_model(naive_bayes_companion_features, naive_test, target=\"Survived\", evaluate=True)\n",
    "print(\"Without companions features:\")\n",
    "evaluate_model(naive_bayes_base, naive_test, target=\"Survived\", evaluate=True)\n",
    "print(\"Only Pclass and Sex:\")\n",
    "evaluate_model(naive_bayes_two_features, naive_test, target=\"Survived\", evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a baseline of 76% to beat!\n",
    "\n",
    "More features seem to be a poor addition so far, but will likely have more effect with models that do not assume the input variables to be independant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum entropy classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier from old university lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    \"\"\"Computes the softmax function for the specified batch of data.\n",
    "\n",
    "    This uses a common trick to improve numerical stability; this trick is\n",
    "    explained here:\n",
    "\n",
    "    http://stackoverflow.com/a/39558290\n",
    "    \"\"\"\n",
    "    E = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
    "    return E / E.sum(axis=1, keepdims=True)\n",
    "\n",
    "def minibatches(X, Y, batch_size):\n",
    "    \"\"\"Yields minibatches from the specified X and Y matrices.\n",
    "\n",
    "    Instead of computing updates on the complete data, it is a good idea\n",
    "    to only compute them on parts of the data; these parts are called\n",
    "    minibatches. This function randomly splits the input data into\n",
    "    minibatches of the specified size.\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    n_batches = int(np.floor(m / batch_size))\n",
    "    np.random.seed(1)\n",
    "    random_indices = np.random.permutation(np.arange(m))\n",
    "    for i in range(n_batches):\n",
    "        batch_indices = np.arange(i * batch_size, (i + 1) * batch_size)\n",
    "        batch_indices = random_indices[batch_indices]\n",
    "        yield X[batch_indices], Y[batch_indices]\n",
    "\n",
    "class MaxentClassifier(object):\n",
    "\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        self.W = np.zeros((n_features, n_classes))\n",
    "\n",
    "    def p(self, X):\n",
    "        \"\"\"Returns the class probabilities for the given input.\"\"\"\n",
    "\n",
    "        return softmax(np.dot(X,self.W))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Returns the most probable class for the given input\"\"\"\n",
    "        activation = np.dot(X,self.W)\n",
    "\n",
    "        return np.argmax(activation, axis=1)\n",
    "\n",
    "    @classmethod\n",
    "    def train(cls, X, Y, n_epochs=1, batch_size=1, eta=0.01, reg=0.1):\n",
    "        classifier = cls(X.shape[1], Y.shape[1])\n",
    "\n",
    "        for e in range(n_epochs):\n",
    "            for batch in minibatches(X,Y,batch_size):\n",
    "                classifier.W = classifier.W + eta*(np.dot(np.transpose(batch[0]), \\\n",
    "                    (batch[1] - classifier.p(batch[0]))) - reg*classifier.W)\n",
    "\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_X_Y(trainf_df, test_df):\n",
    "    X_train = trainf_df.drop('Survived', axis = 1).values\n",
    "    X_test = test_df.drop('Survived', axis = 1).values\n",
    "    # Create dummies for Y [0, 1] = Survived [1, 0] = Dead\n",
    "    Y_train = np.zeros(shape = (len(trainf_df), 2))\n",
    "    for i, x in enumerate(trainf_df['Survived'].values):\n",
    "        Y_train[i][x] = 1\n",
    "    Y_test = np.zeros(shape = (len(test_df), 2))\n",
    "    for i, x in enumerate(test_df['Survived'].values):\n",
    "        Y_test[i][x] = 1\n",
    "    X_train = X_train.astype(float)\n",
    "    X_test = X_test.astype(float)\n",
    "    Y_train = Y_train.astype(float)\n",
    "    Y_test = Y_test.astype(float)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(Y, Y_hat):\n",
    "    correct = n = 0.0\n",
    "    for ans, pred in zip(Y, Y_hat):\n",
    "        n+= 1\n",
    "        if ans[pred]:\n",
    "            correct += 1\n",
    "    print(\"Accuracy on {} samples: {}\".format(n, correct/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First try with the maximum entropy classifer!\n",
    "Let try with our favourite variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', 'Child', 'SurvivingCompanions', 'DeadCompanions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxent_train = prepare_training_data(training_data)[variables + ['Survived']]\n",
    "maxent_test = prepare_test_data(test_data, training_data)[variables + ['Survived']]\n",
    "\n",
    "maxent_train = pd.get_dummies(maxent_train)\n",
    "maxent_test = pd.get_dummies(maxent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 233.0 samples: 0.8283261802575107\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = generate_X_Y(maxent_train, maxent_test)\n",
    "maxent_classifier = MaxentClassifier.train(X_train, Y_train, batch_size = 10, n_epochs=10)\n",
    "Y_hat = maxent_classifier.predict(X_test)\n",
    "accuracy(Y_test, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y = list(map(np.argmax, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x2846fc27ba8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGtCAYAAAABCu4VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAH3BJREFUeJzt3Xm4HHWV8PHvIWEJSdhkMSTsRBGFAQVkEUcHHAWUzQ1H\nERGNKCrKOLKIgzg4CiIOvCKQSUC2AZGXTREUMgqKAkbgDUtAIoiELQgimxjCPe8fXZFrvLnpXLq6\nu6q+nzz1dFdVd9VpnyfkeM7v96vITCRJkqpsmV4HIEmS9FKZ0EiSpMozoZEkSZVnQiNJkirPhEaS\nJFWeCY0kSao8ExpJklR5JjSSJKnyTGgkSVLlje51AIvz/B/ucQljqQfGrL1jr0OQGmvB/Aeim/fr\n5L+1y66+YVdjX5QVGkmSVHl9W6GRJEklG3ih1xF0jBUaSZJUeVZoJElqqhzodQQdY0IjSVJTDdQn\nobHlJEmSKs8KjSRJDZW2nCRJUuXZcpIkSeofVmgkSWoqW06SJKnyXFhPkiSpf1ihkSSpqWw5SZKk\nynOWkyRJUv+wQiNJUkO5sJ4kSao+W06SJEnti4jTI2JeRNw26NjXI+LOiJgVERdHxCqDzh0eEXMi\n4q6IeOuSrm9CI0lSU+VA57Yl+w7wtkWOXQW8JjM3B34DHA4QEZsC+wCvLr7z7YgYNdzFTWgkSWqq\ngRc6ty1BZl4LPL7IsR9n5oJi93pgUvF+D+D8zPxLZt4LzAG2Ge76JjSSJKkffBi4ong/Ebh/0Lm5\nxbHFclCwJElN1cFZThExBZgy6NDUzJza5ne/ACwAzl14aIiP5XDXMKGRJKmpOjjLqUhe2kpgBouI\n/YC3Aztl5sKkZS6wzqCPTQIeHO46tpwkSVJPRMTbgEOB3TPz2UGnLgP2iYjlI2IDYDJw43DXskIj\nSVJTdXFhvYg4D3gTsHpEzAWOojWraXngqogAuD4zD8zM2yPiAuAOWq2ogzJz2JHHJjSSJDVVFxfW\ny8z3DXF4+jCf/wrwlXavb8tJkiRVnhUaSZIaagldnEoxoZEkqalq9HBKW06SJKnyrNBIktRUNXra\ntgmNJElNVaOWkwmNJElN1cZDJavCMTSSJKnyrNBIktRUtpwkSVLl1WhQsC0nSZJUeVZoJElqKltO\nkiSp8mw5SZIk9Q8rNJIkNVWNKjQmNJIkNVSdnrZty0mSJFWeFRpJkprKlpMkSaq8Gk3btuUkSZIq\nzwqNJElNZctJkiRVni0nSZKk/mGFRpKkprLlJEmSKs+WkyRJUv+wQiNJUlPZcpIkSZVXo4TGlpMk\nSao8KzSSJDVVjQYFm9BIktRUtpwkSZL6hxUaSZKaypaTJEmqPFtOkiRJ/cMKjSRJTWXLSZIkVZ4t\nJ0mSpP5hhUaSpKaqUYXGhEaSpKbK7HUEHWPLSZIkVZ4VGkmSmsqWkyRJqrwaJTS2nCRJUuVZoZEk\nqalcWE+SJFWeLSdJkqT+YYVGkqSmqtE6NCY0kiQ1lS0nSZKk/mGFRpKkpqpRhcaERpKkpqrRtG1b\nTpIkqfKs0EiS1FA54CwnSZJUdTUaQ2PLSZIkVZ4VGkmSmqpGg4JNaCRJaqoajaGx5SRJkirPCo0k\nSU1Vo0HBJjSSJDWVCY0kSaq8Gj1t2zE0kiSpdBFxekTMi4jbBh1bLSKuioi7i9dVi+MRESdFxJyI\nmBURr13S9U1oJElqqoGBzm1L9h3gbYscOwyYkZmTgRnFPsAuwORimwKcsqSL23LSUjvyP0/g2utu\nZLVVV+GSc04F4PhvTeOa625g9LKjWWfiBI454hBWGj8OgLvm3MuXjzuJp595lmWWWYbzp53I8ssv\n18ufINXCf0/9BrvtujPzHv0DW2y5EwCbb74p3/7W1xg7bkXuu28u+37wkzz11NM9jlR9q4vTtjPz\n2ohYf5HDewBvKt6fCfwUOLQ4flZmJnB9RKwSERMy86HFXd8KjZbanru+hVNPOOZvjm239ZZcfPap\nXHzWKay/zkSmnf1dABYseIHDvnwcX/y3T3HpuadxxreOZfToUb0IW6qds866gN3e/v6/OXbaqV/n\niC/8J1u+dmcuueQKPvevH+9RdFJb1lqYpBSvaxbHJwL3D/rc3OLYYpWW0ETEJhFxaNEDO7F4/6qy\n7qfu2WqLzVh5pfF/c2yH17/ur4nK5q/ehEfm/QGAX9z4a16x0QZsMnlDAFZZeSVGjTKhkTrhZz+/\ngcf/+MTfHHvlKzbi2p9dD8DVM37GXnvt2ovQVBU50LEtIqZExMxB25SXEFkMFe1wXygloYmIQ4Hz\ni4BuBH5VvD8vIg4b7ruqvosv/zFv2G5rAO67/wEigimf/QLv3v+TnH7u93ocnVRvt99+F+94xz8D\n8K53vp11Jq3d44jU1wayY1tmTs3MrQZtU9uI4JGImABQvM4rjs8F1hn0uUnAg8NdqKwKzQHA1pn5\ntcw8p9i+BmxTnBvS4Oxu2lnnlRSaynTamecxatQo3v7PbwZgwQsvcPOs2zn2qM9z1inHM+OaX3D9\nzJt7HKVUXx+ZcgifOPBD3HD9FYwfP5b585/vdUjScC4D9ive7wdcOuj4B4vZTtsCfxpu/AyUNyh4\nAFgbuG+R4xOKc0MqsrmpAM//4Z76TI5viEt/eBXXXncj0076KhGtauFaa67OVltsxqqrrAzAjttt\nzR13/ZZtt9qyl6FKtXXXXb9ll93+BYDJkzdk11126nFE6mfZxYX1IuI8WgOAV4+IucBRwNeACyLi\nAOD3wLuLj/8Q2BWYAzwL7L+k65eV0HwGmBERd/PioJ51gY2BT5Z0T/XQz6+fyfRzv8d3vnUcY1ZY\n4a/Hd9jmdZxx7oX8+bnnWHb0ssy85Vb2fe9ePYxUqrc11ngZjz76GBHBEYcfzGlTz+51SOpn3Z3l\n9L7FnPq7rLuY3XTQ0ly/lIQmM6+MiFfQajFNpDV+Zi7wq8x8oYx7qnv+7aiv8aubZ/HEE0+y054f\n4BMH7Mu0s7/L/Oef56Of+QLQGhh81Oc/xcorjeeD++zNPgccTESw43Zb84/bb9PjXyDVwzlnn8w/\nvnE7Vl99NX53z0yO/vLxjBs3lo9//EMAXHLJD/nOmd/tbZBSl0T26bLHtpyk3hiz9o69DkFqrAXz\nHxhqdk9pnjnmAx37t3bsked0NfZFubCeJElN1cWWU9lcWE+SJFWeFRpJkpqqi7OcymZCI0lSU9ly\nkiRJ6h9WaCRJaqq05SRJkqrOlpMkSVL/sEIjSVJDdfNZTmUzoZEkqalsOUmSJPUPKzSSJDVVjSo0\nJjSSJDVVjaZt23KSJEmVZ4VGkqSmsuUkSZKqLmuU0NhykiRJlWeFRpKkpqpRhcaERpKkpqrRSsG2\nnCRJUuVZoZEkqalsOUmSpMqrUUJjy0mSJFWeFRpJkhoqsz4VGhMaSZKaypaTJElS/7BCI0lSU9Wo\nQmNCI0lSQ/ksJ0mSpD5ihUaSpKaqUYXGhEaSpKaqz6OcbDlJkqTqs0IjSVJD1WlQsAmNJElNVaOE\nxpaTJEmqPCs0kiQ1VY0GBZvQSJLUUHUaQ2PLSZIkVZ4VGkmSmsqWkyRJqjpbTpIkSX3ECo0kSU1l\ny0mSJFVdmtBIkqTKq1FC4xgaSZJUeVZoJElqKFtOkiSp+mqU0NhykiRJlWeFRpKkhrLlJEmSKq9O\nCY0tJ0mSVHlWaCRJaqjGVWgiYr2I2Ll4PyYixpcbliRJKl1G57YeW2JCExEfBS4ETisOTQIuKTMo\nSZKkpdFOy+kgYBvgBoDMvDsi1iw1KkmSVLo6tZzaSWj+kpnzI1rlpIgYDWSpUUmSpNLlQO9bRZ3S\nzhiaayLiCGBMRLwF+B7w/XLDkiRJal87Cc1hwKPArcDHgB8CR5YZlCRJKl8OdG7rtSW2nDJzAPjv\nYpMkSTWRfTA7qVOWmNBExL0MMWYmMzcsJSJJkqSl1M6g4K0GvV8BeDewWjnhSJKkbulmqygiPgt8\nhFaR5FZgf2ACcD6tvOImYN/MnD+S6y9xDE1mPjZoeyAz/wv4p5HcTJIk9Y8ciI5tw4mIicCnga0y\n8zXAKGAf4Fjgm5k5GfgjcMBIf0s7LafXDtpdhlbFxpWCJUnS0hhNa8b088CKwEO0CiT/Upw/E/gS\ncMpIL74k3xj0fgHwO+A9I7mZJEnqH9mlVeUy84GIOB74PfBn4MfAr4EnMnNB8bG5wMSR3qOdWU5v\nHunFJUlS/+rkwnoRMQWYMujQ1MycWpxbFdgD2AB4gtaadrsMFdJI77/YhCYiDhnui5l5wkhvKkmS\n6qVIXqYu5vTOwL2Z+ShARFwEbA+sEhGjiyrNJODBkd5/uAqN42QkSaqxLj764PfAthGxIq2W007A\nTOAnwLtozXTaD7h0pDdYbEKTmUeP9KKSJKn/dXEMzQ0RcSGtqdkLgJtpVXMuB86PiGOKY9NHeo92\nZjmtQGsa1atprUOzMLgPj/SmkiSpWTLzKOCoRQ7fA2zTieu38yyns4GXA28FrqHV43qqEzeXJEm9\n0611aLqhnYRm48z8IvBMZp4J7AZsVm5YkiSpbJnRsa3X2kloni9en4iI1wArA+uXFpEkSdJSamdh\nvanF/PEjgcuAccAXS41KkiSVrpvPcirbcOvQrJWZj2TmtOLQtYBP2JYkqSYG+qBV1CnDtZz+X0Rc\nFREfjoiVuxaRJEnSUhouoZkIHA/sCPwmIi6JiPdGxJjuhCZJksrUiEHBmflCZv4oM/cH1gHOAPYE\n7o2Ic7sVoCRJKkfTpm2TmfOBO4DZwJPApmUGJUmStDSGneUUEesC7wXeB4yl9ayFPTJzdhdikyRJ\nJerWow+6YbhZTr+gNY7me8CUzJzZtagkSVLp+qFV1CnDVWgOB67NrFP+JkmS6mi4p21f081AJElS\nd9VpHZp2VgqWJEk11A/TrTulrVlOkiRJ/Wy4QcGHDPfFzDyh8+FIkqRuqdMo2eFaTuOL11cCW9N6\nMCXAO2g910mSJFVYI8bQZObRABHxY+C1mflUsf8lWlO5JUmS+kI7g4LXBeYP2p8PrF9KNJIkqWvq\nNCi4nYTmbODGiLgYSGAv4KxSo5IkSaVryhgaADLzKxFxBa2nbgPsn5k3lxuWJElS+9pdh2ZF4MnM\nPCMi1oiIDTLz3jIDGz/pTWVeXtJiXLbqjkv+kKRaaMSg4IUi4ihgK1qznc4AlgXOAXYoNzRJklSm\nOo2haWdhvb2A3YFnADLzQV6c0i1JktRz7bSc5mdmRkQCRMTYkmOSJEldUKeWUzsVmgsi4jRglYj4\nKHA1MK3csCRJUtmyg1uvtTPL6fiIeAvwJK1xNP+emVeVHpkkSSpVnSo07QwKPjYzDwWuGuKYJElS\nz7XTcnrLEMd26XQgkiSpuzKjY1uvDfe07Y8DnwA2iohZg06NB35RdmCSJKlcA70OoIOGazn9D3AF\n8FXgsEHHn8rMx0uNSpIkaSkM97TtPwF/iogTgccHPW17fES8PjNv6FaQkiSp85Let4o6pZ0xNKcA\nTw/af6Y4JkmSKmwgO7f1WjsJTWS++DzOzByg/WdASZIkla6dhOaeiPh0RCxbbAcD95QdmCRJKtcA\n0bGt19pJaA4EtgceAOYCrwemlBmUJEkqXxId23qtnZWC5wH7dCEWSZKkERluHZrPZ+ZxEfF/GOIx\nDZn56VIjkyRJpWrKOjSzi9eZ3QhEkiR1Vz+0ijpluHVovl+8ntm9cCRJkpbecC2n7zPME8Ezc/dS\nIpIkSV3RlJbT8cXr3sDLgXOK/fcBvysxJkmS1AWNSGgy8xqAiPiPzHzjoFPfj4hrS49MkiSpTe2s\nQ7NGRGy4cCciNgDWKC8kSZLUDY1ahwb4LPDTiFi4OvD6wMdKi0iSJHXFQO/zkI5pZ2G9KyNiMrBJ\ncejOzPxLuWFJkiS1b4kJTUSsCBwCrJeZH42IyRHxysz8QfnhSZKksvTDM5g6pZ0xNGcA84Htiv25\nwDGlRSRJkroiO7j1WjsJzUaZeRzwPEBm/hlqlNJJkqTKa2dQ8PyIGEORgEXERoBjaCRJqrhGrEMz\nyFHAlcA6EXEusAPwoTKDkiRJ5RuI+jRchk1oIiKAO2mtFrwtrVbTwZn5hy7EJkmS1JZhE5rMzIi4\nJDNfB1zepZgkSVIX9MNg3k5pZ1Dw9RGxdemRSJKkrhro4NZr7YyheTNwYET8DniGVtspM3PzMgOT\nJElqVzsJzS6lRyFJkrquEY8+iIgVgAOBjYFbgemZuaBbgUmSpHI1ZaXgM4GtaCUzuwDf6EpEkiRJ\nS2m4ltOmmbkZQERMB27sTkiSJKkb6jTLabiE5vmFbzJzQdRo8R1JktSQMTTAP0TEk8X7AMYU+wtn\nOa1UenSSJEltWGxCk5mjuhmIJEnqrn5YP6ZT2llYT5Ik1VB2cFuSiFglIi6MiDsjYnZEbBcRq0XE\nVRFxd/G66kh/iwmNJEnqhhOBKzNzE+AfgNnAYcCMzJwMzCj2R8SERpKkhhqIzm3DiYiVgDcC0wEy\nc35mPgHsQWuZGIrXPUf6W0xoJElqqC4+y2lD4FHgjIi4OSKmRcRYYK3MfAigeF1zpL/FhEaSJL1k\nETElImYO2qYMOj0aeC1wSmZuSevZkCNuLw2lnWc5SZKkGurkLKfMnApMXczpucDczLyh2L+QVkLz\nSERMyMyHImICMG+k97dCI0lSQ2V0bhv2PpkPA/dHxCuLQzsBdwCXAfsVx/YDLh3pb7FCI0mSuuFT\nwLkRsRxwD7A/rcLKBRFxAPB74N0jvbgJjSRJDdXNhfUy8xZaD71e1E6duL4JjSRJDeVKwZIkSX3E\nCo0kSQ3VziMLqsKERpKkhlrSCr9VYstJkiRVnhUaSZIaqk6Dgk1oJElqqDolNLacJElS5VmhkSSp\noZzlJEmSKq9Os5xMaCRJaijH0EiSJPURKzSSJDWUY2gkSVLlDdQopbHlJEmSKs8KjSRJDVWnQcEm\nNJIkNVR9Gk62nCRJUg1YoZEkqaFsOUmSpMqr00rBtpwkSVLlWaGRJKmh6rQOjQmNJEkNVZ90xpaT\nJEmqASs0kiQ1lLOcJElS5dVpDI0tJ0mSVHlWaCRJaqj61GdMaCRJaqw6jaGx5SRJkirPCo0kSQ1V\np0HBJjSSJDVUfdIZW06SJKkGrNBIktRQdRoUbEIjSVJDZY2aTracJElS5VmhkSSpoWw5SZKkyqvT\ntG1bTpIkqfKs0EiS1FD1qc+Y0EiS1Fh1ajmZ0OglmTRpAtOnf5O11lqDgYFk+vT/4eSTT2fvvXfj\nyCM/yyabbMwb3rA7N900q9ehSrUzeqUV2eyEjzF+k0mQMOuzp7L+lF0Zt9GE4vxYFjz5DD/f6bAe\nRyqVz4RGL8mCBS9w6KHHcMsttzFu3Fh++cvLmTHjZ9x++128971TOPnkr/Y6RKm2Nj1mPx79yS3c\n/JFvEsuOYtSY5bllyol/Pb/Jlz7Agief7WGE6nd1muXkoGC9JA8/PI9bbrkNgKeffoY775zDxIkv\n56675nD33ff0ODqpvkaPG8Nq272Kuef+BIB8/oW/S14m7L4dD178i16Ep4rIDv7pta4nNBGxf7fv\nqe5Yb71JbLHFq7nxxpt7HYpUe2PWW5P5jz3J5id+nB2u/iqbnTCFUSsu/9fzq267CfMffYJn7324\nh1FK3dOLCs3RPbinSjZ27Iqcd95pfO5zR/PUU0/3Ohyp9pYZPYqVNtuA+868iut2PpwFz/6FDT+1\nx1/Pr73XDlZntEQDHdx6rZQxNBGxuBGgAaw1zPemAFMARo9elVGjxpUQnTpt9OjRnH/+aZx//sVc\neumVvQ5HaoQ/P/gYzz34OH+6aQ4AD3//Bjb61O4AxKhlePluW3PdW47oZYiqgH5oFXVKWYOC1wLe\nCvxxkeMBLPb/MmTmVGAqwAorrFuf/5Vr7rTTvs6dd87hpJOm9ToUqTHmP/onnnvwMcZuNIFnfvsQ\nq+/4Gp7+zQMAvOyNm/H03Q/y3EOP9zhKqXvKSmh+AIzLzFsWPRERPy3pnuqB7bffmve//53ceuts\nbrjhCgD+/d+PY/nll+OEE77MGmusxsUXn8GsWXfwjnfs2+NopXq5/Ygz2OLbnySWG82z981j1sGn\nArD2ntvzkO0mtaEfWkWdEpn9WQixQiP1xkUrb9/rEKTG2vWR86Ob99t3vb079m/t2fdd1NXYF+W0\nbUmSVHkurCdJUkPVqRViQiNJUkPV6VlOtpwkSVLlWaGRJKmhXIdGkiRVXp2mbdtykiRJlWeFRpKk\nhqrToGATGkmSGqpOY2hsOUmSpMqzQiNJUkPVaVCwCY0kSQ3Vr89zHAlbTpIkqfJMaCRJaqgBsmNb\nOyJiVETcHBE/KPY3iIgbIuLuiPhuRCw30t9iQiNJUkMNdHBr08HA7EH7xwLfzMzJwB+BA0b6W0xo\nJElqqOzgnyWJiEnAbsC0Yj+AfwIuLD5yJrDnSH+LCY0kSXrJImJKRMwctE1Z5CP/BXyeFws6LwOe\nyMwFxf5cYOJI7+8sJ0mSGqqTKwVn5lRg6lDnIuLtwLzM/HVEvGnh4aEuM9L7m9BIktRQXZy2vQOw\ne0TsCqwArESrYrNKRIwuqjSTgAdHegNbTpIkqVSZeXhmTsrM9YF9gP/NzPcDPwHeVXxsP+DSkd7D\nhEaSpIbqwSynRR0KHBIRc2iNqZk+0gvZcpIkqaF68XDKzPwp8NPi/T3ANp24rhUaSZJUeVZoJElq\nqE7Ocuo1ExpJkhrKh1NKkiT1ESs0kiQ1lC0nSZJUeb2Y5VQWW06SJKnyrNBIktRQAzUaFGxCI0lS\nQ9UnnbHlJEmSasAKjSRJDeUsJ0mSVHl1SmhsOUmSpMqzQiNJUkPV6dEHJjSSJDWULSdJkqQ+YoVG\nkqSGqtOjD0xoJElqqDqNobHlJEmSKs8KjSRJDVWnQcEmNJIkNZQtJ0mSpD5ihUaSpIay5SRJkiqv\nTtO2bTlJkqTKs0IjSVJDDdRoULAJjSRJDWXLSZIkqY9YoZEkqaFsOUmSpMqz5SRJktRHrNBIktRQ\ntpwkSVLl2XKSJEnqI1ZoJElqKFtOkiSp8mw5SZIk9RErNJIkNVTmQK9D6BgTGkmSGmrAlpMkSVL/\nsEIjSVJDpbOcJElS1dlykiRJ6iNWaCRJaihbTpIkqfLqtFKwLSdJklR5VmgkSWqoOj36wIRGkqSG\ncgyNJEmqPKdtS5Ik9RErNJIkNZQtJ0mSVHlO25YkSeojVmgkSWooW06SJKnynOUkSZLUR6zQSJLU\nULacJElS5TnLSZIkqY9YoZEkqaF8OKUkSao8W06SJEl9xIRGkqSGysyObcOJiHUi4icRMTsibo+I\ng4vjq0XEVRFxd/G66kh/iwmNJEkNlR38swQLgH/NzFcB2wIHRcSmwGHAjMycDMwo9kfEhEaSJJUq\nMx/KzJuK908Bs4GJwB7AmcXHzgT2HOk9HBQsSVJDdXJhvYiYAkwZdGhqZk4d4nPrA1sCNwBrZeZD\nRSwPRcSaI72/CY0kSQ3VyYSmSF7+LoEZLCLGAf8X+ExmPhkRHbu/LSdJklS6iFiWVjJzbmZeVBx+\nJCImFOcnAPNGen0TGkmSGio7uA0nWqWY6cDszDxh0KnLgP2K9/sBl470t0SdHkyl/hERU4bqnUoq\nl3/31I8i4g3Az4BbgYHi8BG0xtFcAKwL/B54d2Y+PqJ7mNCoDBExMzO36nUcUtP4d09NZctJkiRV\nngmNJEmqPBMalcUevtQb/t1TIzmGRpIkVZ4VGkmSVHkmNOqoiHhbRNwVEXMiYsQPGZO0dCLi9IiY\nFxG39ToWqRdMaNQxETEKOBnYBdgUeF/xNFVJ5fsO8LZeByH1igmNOmkbYE5m3pOZ84HzaT1JVVLJ\nMvNaYEQLkkl1YEKjTpoI3D9of25xTJKkUpnQqJOGemyq0+gkSaUzoVEnzQXWGbQ/CXiwR7FIkhrE\nhEad9CtgckRsEBHLAfvQepKqJEmlMqFRx2TmAuCTwI+A2cAFmXl7b6OSmiEizgN+CbwyIuZGxAG9\njknqJlcKliRJlWeFRpIkVZ4JjSRJqjwTGkmSVHkmNJIkqfJMaCRJUuWZ0EgVEBEvi4hbiu3hiHhg\n0P5yHbrH+Ih4LCLGLXL8BxGx9zDf2zkiLulEDJI0UqN7HYCkJcvMx4AtACLiS8DTmXn84M9ERNBa\nimFghPd4KiL+l9YDRc8trrkq8HrgXSOPXpLKZ4VGqrCI2DgibouIU4GbgHUi4olB5/eJiGnF+7Ui\n4qKImBkRN0bEtkNc8jxaKzwv9E7g8sx8LiK2jYhfRsTNEXFdREweIp5jIuIzg/bvjIhJxfv9ivve\nEhHfjgj/+yOpY/wPilR9mwLTM3NL4IFhPncScFxmbgW8B5g2xGcuB7YtKjPQSm7OK97PBt5Q3Oc/\ngGPaDTAiXgPsBWyfmVvQqg7vM/y3JKl9tpyk6vttZv6qjc/tTGtZ/IX7q0bEmMz888IDmfmXiLgc\n2DsifgC8GphRnF4FOCsiNhpBjDsDWwMzi/uPAe4fwXUkaUgmNFL1PTPo/QAQg/ZXGPQ+gG0yc/4S\nrnce8DlaScdFxTO6AL4C/Cgzvx0RGwNXDvHdBfxt5Xfh/QM4PTO/uIR7S9KI2HKSaqQYEPzHiJhc\njFHZa9Dpq4GDFu5ExBaLuczVtCozB/JiuwlgZV5saX1oMd/9HfC64vrbAOsMuuZ7ImL14tzLImLd\n9n6VJC2ZCY1UP4fSqp7MAOYOOn4QsENEzIqIO4CPDvXlzHwBuBhYCbhu0Kljga9HxHVDfa/wPWCt\niLgZOAC4p7jmrcDRwNURMQv4MbDWCH6bJA3Jp21LkqTKs0IjSZIqz4RGkiRVngmNJEmqPBMaSZJU\neSY0kiSp8kxoJElS5ZnQSJKkyjOhkSRJlff/AcpWsm4SiXmoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2846f62a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusing_matrix_df = pd.DataFrame(confusion_matrix(test_Y, Y_hat))\n",
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "sns.heatmap(confusing_matrix_df, annot=True, fmt=\".0f\", ax = ax)\n",
    "ax.set_xlabel('True Value')\n",
    "ax.set_ylabel('Predicted Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improved accuracy! Woho!\n",
    "\n",
    "Lets check out the weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = maxent_train.drop('Survived', axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dead</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>-0.764988</td>\n",
       "      <td>0.764988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SurvivingCompanions</th>\n",
       "      <td>-0.461305</td>\n",
       "      <td>0.461305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mrs</th>\n",
       "      <td>-0.443335</td>\n",
       "      <td>0.443335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Master</th>\n",
       "      <td>-0.441814</td>\n",
       "      <td>0.441814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>-0.363600</td>\n",
       "      <td>0.363600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Child</th>\n",
       "      <td>-0.272675</td>\n",
       "      <td>0.272675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Miss</th>\n",
       "      <td>-0.251113</td>\n",
       "      <td>0.251113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.215614</td>\n",
       "      <td>0.215614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>-0.205187</td>\n",
       "      <td>0.205187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-0.040051</td>\n",
       "      <td>0.040051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.051653</td>\n",
       "      <td>-0.051653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Other</th>\n",
       "      <td>0.072995</td>\n",
       "      <td>-0.072995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.073561</td>\n",
       "      <td>-0.073561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.234337</td>\n",
       "      <td>-0.234337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mr</th>\n",
       "      <td>0.258229</td>\n",
       "      <td>-0.258229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeadCompanions</th>\n",
       "      <td>0.274855</td>\n",
       "      <td>-0.274855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dead  Survived\n",
       "Sex_female          -0.764988  0.764988\n",
       "SurvivingCompanions -0.461305  0.461305\n",
       "Title_Mrs           -0.443335  0.443335\n",
       "Title_Master        -0.441814  0.441814\n",
       "Embarked_C          -0.363600  0.363600\n",
       "Child               -0.272675  0.272675\n",
       "Title_Miss          -0.251113  0.251113\n",
       "Embarked_S          -0.215614  0.215614\n",
       "Embarked_Q          -0.205187  0.205187\n",
       "Sex_male            -0.040051  0.040051\n",
       "SibSp                0.051653 -0.051653\n",
       "Title_Other          0.072995 -0.072995\n",
       "Parch                0.073561 -0.073561\n",
       "Pclass               0.234337 -0.234337\n",
       "Title_Mr             0.258229 -0.258229\n",
       "DeadCompanions       0.274855 -0.274855"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=features, data=maxent_classifier.W, columns=['Dead', 'Survived']).sort_values('Dead')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SibSp, Parch, Sex_male and Title_Other have very low values. This means they contribute little to the outcome. Ltes try to drop them! (Intuitively it seems like a bad move to drop just some values of a categorical, but lets experiment!)\n",
    "\n",
    "For the ordinal variables SibSp and Parch this might also be misguided, as potentially their weight can contribute more when they have higher values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second go, dropping variables with low impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove SibSP, Parch, Sex_male and Title_Other\n",
    "remove_indexes = [1, 2, 7, 15]\n",
    "mask = [False if i in remove_indexes else True for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 233.0 samples: 0.8240343347639485\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = generate_X_Y(maxent_train, maxent_test)\n",
    "X_train = X_train[:,mask]\n",
    "X_test = X_test[:,mask]\n",
    "maxent_classifier = MaxentClassifier.train(X_train, Y_train, batch_size = 10, n_epochs=10)\n",
    "Y_hat = maxent_classifier.predict(X_test)\n",
    "accuracy(Y_test, Y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost the same accuracy! Lets try keeping our ordinal variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove SibSP, Parch, Sex_male and Title_Other\n",
    "remove_indexes = [7, 15]\n",
    "mask = [False if i in remove_indexes else True for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 233.0 samples: 0.8283261802575107\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = generate_X_Y(maxent_train, maxent_test)\n",
    "X_train = X_train[:,mask]\n",
    "X_test = X_test[:,mask]\n",
    "maxent_classifier = MaxentClassifier.train(X_train, Y_train, batch_size = 10, n_epochs=10)\n",
    "Y_hat = maxent_classifier.predict(X_test)\n",
    "accuracy(Y_test, Y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shady business removing some categories of our ordinals, and we don't seem to achieve better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try the actual test set!\n",
    "My feature `Surviving Companions` should be more effectfull with more data in the training set. Lets see what results I get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_ = pd.read_csv('titanic_train.csv')\n",
    "test_data_ = pd.read_csv('titanic_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', 'Child', 'SurvivingCompanions', 'DeadCompanions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = prepare_training_data(training_data_)[variables + ['Survived']]\n",
    "test_data = prepare_test_data(test_data_, training_data_)[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxent_train = pd.get_dummies(training_data)\n",
    "maxent_test = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = generate_X_Y(maxent_train, maxent_test)\n",
    "maxent_classifier = MaxentClassifier.train(X_train, Y_train, batch_size = 10, n_epochs=10)\n",
    "Y_hat = maxent_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(index = test_data_['PassengerId'], data=Y_hat, columns=['Survived']).to_csv('titanic_submission1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: **0.80382 test score**. I can do better!  \n",
    "\n",
    "I want to improve on these fronts:\n",
    "* Explore and improve my features\n",
    "* Investigate crossvalidation as a means of tuning my model parameters\n",
    "* Test other predictive models\n",
    "\n",
    "I will continue in another notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

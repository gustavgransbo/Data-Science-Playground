{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "Recent advances in Machine Learning allows computers to perform tasks that were previously believed to require human inuition. \n",
    "Could generating a quiz to gauge reading comprehension be such a task?\n",
    "\n",
    "In this notebook I present an approach to generate simple fact questions based on text data.\n",
    "Example questions:\n",
    "* Carl XVI Gustaf born in _year_\n",
    "* In 1976 Carl XVI Gustaf married _person_\n",
    "\n",
    "Ideally the questions would be reformatted as:\n",
    "* When was Carl XVI Gustaf born?\n",
    "* Who did Carl XVI Gustaf marry in 1976?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "Raw text data is pre-processed and dependency graphs are construced for each sentence. \n",
    "[Here](https://ai.googleblog.com/2016/05/announcing-syntaxnet-worlds-most.html) is a good resource from Google introducing the concept of dependency parsing.\n",
    "Dependency graphs provide a structured representation of sentence semantics, from which we will extract relations to turn into questions.\n",
    "\n",
    "A question will be generated from a relationship by withholding part of the relation ship.\n",
    "For example:\n",
    "\"Carl was born in Sweden\" could be turned into the question \"Carl was born in _location_\"\n",
    "\n",
    "Dependency graphs for a text can be created using a custom dependency parser, or a pre-trained one.\n",
    "In this notebook I will use the [Stanford Parser](https://nlp.stanford.edu/software/lex-parser.shtml#Sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "\n",
    "path = '../stanford_parser'\n",
    "\n",
    "path_to_jar = path + '/stanford-parser-full-2018-02-27/stanford-parser-full-2018-02-27/stanford-parser.jar'\n",
    "path_to_models_jar = path + '/stanford-parser-full-2018-02-27/stanford-parser-full-2018-02-27/stanford-english-corenlp-2018-02-27-models.jar'\n",
    "#path_to_models_jar = path + '/stanford-english-corenlp-2018-02-27-models.jar'\n",
    "\n",
    "dependency_parser = StanfordDependencyParser(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = dependency_parser.raw_parse('Carl XVI Gustaf was born in 1946.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "compound(Gustaf-3, Carl-1)\n",
    "compound(Gustaf-3, XVI-2)\n",
    "nsubjpass(born-5, Gustaf-3)\n",
    "auxpass(born-5, was-4)\n",
    "root(ROOT-0, born-5)\n",
    "case(1946-7, in-6)\n",
    "nmod:in(born-5, 1946-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "1. Build logic to truncate dependency tree to core components that will be used in questions\n",
    "2. Build logic to withhold relevant parts of tree in order to generate a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations\n",
    "The model in it's current form has several limitations.\n",
    "I divide these into two categories: inherent limitations and extendable limitations.\n",
    "The inherent limitations are hard to adress without a major overhaul of the model, the extendable limitations could more easily be adressed with extensions to the model.\n",
    "\n",
    "Inherent limitations:\n",
    "* The model only asks fact based questions, which limits the depth of understanding it's questions can gauge.\n",
    "* Questions are generated based on pre defined rules, the model does not learn anything about asking questions.\n",
    "* The model requires dependency parsed input. A parser with sufficient performance in the relevant language is necessary.\n",
    "\n",
    "Extendable limitations:\n",
    "* The models understanding of a text is limited to direct semantic relationships within a single sentence. \n",
    "    * It does not understand that two mentions of the same named entity represent the same entity.\n",
    "    * It does not attempt to understand co-references such as \"**Carl** was born 1946, **he** was crowned 1973\".\n",
    "* The question format is limited to fill in the blank type questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending the Model\n",
    "The model in it's current state is very limited in what questions it can generate. \n",
    "There are some low haning fruits that could extend it's undertsnding of a text and allow a little bit more complex questiosn to be generated.\n",
    "## Improving the Question Format\n",
    "A simple method of improving the question format would be to create rules based on what kind of information is withheld.\n",
    "If the location in a relationship like \"Entity Verb Location\" is withheld then the question might be formulated like \"Where did Entity Verb?\" etc.\n",
    "\n",
    "This method is limited in that it requires human engineered rules.\n",
    "However, having human engineered rules might be a good to ensure the quality of questions.\n",
    "If this is the case then this method might not add many additional restrictions.\n",
    "## Connecting Named Entities\n",
    "If a named entity appears in multiple statements the model should be able to connect the this knowledge. \n",
    "For example, if the model reads the text \"Carl is the king of Sweden. Carl was born 1946.\" it should be able to connect these two facts about Carl and form a question like: \"When was the king of Sweden born?\".\n",
    "Such relations could be represented by a simple relational database or.\n",
    "The challenge is detecting words that should be deemed to represent the same entity.\n",
    "This problem is called co-reference resolution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

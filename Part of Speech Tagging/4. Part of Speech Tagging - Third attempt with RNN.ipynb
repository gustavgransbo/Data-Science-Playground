{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In `3. Part of Speech Tagging - Second attempt with RNN` I did Part of Speech (POS) tagging with several RNN's. My most successful was inspired by [Wang et al., 2015](https://arxiv.org/pdf/1510.06168.pdf), who used a model originally from [Graves, 2012](https://www.cs.toronto.edu/~graves/preprint.pdf):\n",
    "Two LSTM layers with 93 hidden units, one doing a forward pass of the input and the other a backward pass. \n",
    "\n",
    "I encoded all words using word embeddings trained by [Glove](https://nlp.stanford.edu/projects/glove/). Glove is Stanfords embedding model.\n",
    "\n",
    "In this notebook I will use a similar approach, but this time I will implement my model in PyTorch. Hopefully increased control will help me to learn an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data\n",
    "I will be using the same training data for my tagger as in all my previous notebooks:\n",
    "[Universal Dependencies - English Web Treebank](http://universaldependencies.org/treebanks/en_ewt/index.html), a CoNLL-U formart corpus with 254 830 words and 16 622 sentences in english *taken from various web media including weblogs, newsgroups, emails, reviews, and Yahoo! answers*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "First lets load the training data and convert it to a python dictionary.\n",
    "I use the [conllu](https://github.com/EmilStenstrom/conllu) python package to parse the CoNLL-U files to dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import conllu\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'UD/UD_English-EWT'\n",
    "with open('{}/en_ewt-ud-train.conllu'.format(directory), 'r', encoding='utf-8') as f:\n",
    "    train_text = f.read()\n",
    "    \n",
    "directory = 'UD/UD_English-EWT'\n",
    "with open('{}/en_ewt-ud-dev.conllu'.format(directory), 'r', encoding='utf-8') as f:\n",
    "    dev_text = f.read()\n",
    "    \n",
    "directory = 'UD/UD_English-EWT'\n",
    "with open('{}/en_ewt-ud-test.conllu'.format(directory), 'r', encoding='utf-8') as f:\n",
    "    test_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dict = conllu.parse(train_text)\n",
    "dev_dict = conllu.parse(dev_text)\n",
    "test_dict = conllu.parse(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count sentences and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set contains 12543 sentences and 204607 tokens\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "n_train_sentences = len(train_dict)\n",
    "n_train_tokens = reduce(lambda x, y: x + len(y), train_dict, 0)\n",
    "\n",
    "print(\"The training set contains {} sentences and {} tokens\".format(n_train_sentences, n_train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = [[token['form'] for token in sentence] for sentence in train_dict]\n",
    "train_labels = [[token['upostag'] for token in sentence] for sentence in train_dict]\n",
    "\n",
    "dev_sentences = [[token['form'] for token in sentence] for sentence in dev_dict]\n",
    "dev_labels = [[token['upostag'] for token in sentence] for sentence in dev_dict]\n",
    "\n",
    "test_sentences = [[token['form'] for token in sentence] for sentence in test_dict]\n",
    "test_labels = [[token['upostag'] for token in sentence] for sentence in test_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tags = list(set(reduce(lambda x, y: x + y, train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labels = len(pos_tags)\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "[Wang et al.](https://arxiv.org/pdf/1510.06168.pdf) showed that a bidirectional LSTM network could achieve state of the art performance without using any morphological features, they only used these features:\n",
    "* Word embedding of the word (cast to lower case). Embeddings trained by the same architecture, but on another task.\n",
    "* Suffix of length two, one-hot encoded\n",
    "* Wether the word is all caps, lower case, or has an initial capital letter. One-hot encoded.\n",
    "\n",
    "Other papers, like [Xiao et al.](https://arxiv.org/abs/1809.01997), complement word embeddings with character embeddings. \n",
    "It would be interesting to experiment with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove\n",
    "I will opt to use the 100 dimensional Glove 6B data. My vocabulary will be exactly the words inside the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_path = 'glove/glove.6B/glove.6B.100d.txt'\n",
    "embeddings = {}\n",
    "token_index = {}\n",
    "index_token = {}\n",
    "with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        tok, *vec = line.split()\n",
    "        embeddings[tok] = np.array(vec, dtype='float32')\n",
    "        # Reserve index 0 for padding\n",
    "        token_index[tok] = i + 1\n",
    "        index_token[i+1] = tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know from my last notebook that my data has many words that are OOV for Glove. I adressed this by pre-processing my data. In this notebook I will condense my preprocessing to a single method, check the other one for more rationale on why I apply each step.\n",
    "\n",
    "I will apply pre-processing to all three data sets: train, dev and test. As the preprocessing is not trained on the data this could be done on new data in production as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def allign_to_vocab(vocab, sentences):\n",
    "    \n",
    "    # Find all OOV tokens\n",
    "    oov = find_oov(vocab, sentences)\n",
    "    print(\"%d OOV tokens before processing\" % len(oov))\n",
    "    \n",
    "    # Convert to lower case\n",
    "    sentences = [[token.lower() for token in sentence] for sentence in sentences]\n",
    "    \n",
    "    oov = find_oov(vocab, sentences)\n",
    "    print(\"%d OOV tokens after converting to lower case\" % len(oov))\n",
    "    \n",
    "    # Replace URL's with 'url'\n",
    "    sentences = [[convert_url(token) for token in sentence] for sentence in sentences]\n",
    "    \n",
    "    oov = find_oov(vocab, sentences)\n",
    "    print(\"%d OOV tokens after converting urls\" % len(oov))\n",
    "    \n",
    "    # Build spelling correction dictionary\n",
    "    # Search for word in vocabulary words within 1 Levensthein Damerau distance\n",
    "    new_spelling = dict([(word, find_one_neighbour(word, embeddings)) for word in oov])\n",
    "    sentences = [[new_spelling[token] if token in new_spelling else token for token in sentence] for sentence in sentences]\n",
    "    \n",
    "    oov = find_oov(vocab, sentences)\n",
    "    print(\"%d OOV tokens after spelling correction\" % len(oov))\n",
    "    \n",
    "    # Replace OOV words with 'unk'\n",
    "    # See https://stackoverflow.com/questions/49239941/what-is-unk-in-glove-6b-50d-txt\n",
    "    sentences = [['unk' if token in oov else token for token in sentence] for sentence in sentences]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def find_oov(vocab, sentences):\n",
    "    oov = []\n",
    "    for sentence in sentences:\n",
    "        for tok in sentence:\n",
    "            if tok not in vocab:\n",
    "                oov.append(tok)\n",
    "    return oov\n",
    "     \n",
    "def convert_url(token):\n",
    "    # Match words starting with www., http:// or https://\n",
    "    if re.match(r'^(?:https{0,1}\\:\\/\\/.*|www\\.*)', token):\n",
    "        return \"url\"\n",
    "    else:\n",
    "        return token\n",
    "\n",
    "# Checks for vocabulary words within 1 Damerau Levenstein distance and returns the first match\n",
    "# Logic inspired by http://norvig.com/spell-correct.html\n",
    "def find_one_neighbour(word, vocab):\n",
    "    \n",
    "    ascii_vocab = [str(chr(i)) for i in range(32, 127)]\n",
    "    \n",
    "    # Tuples with all possible splits of word\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    \n",
    "    # All words generated by deleting one character\n",
    "    for L, R in splits:\n",
    "        candidate = L + R[1:] if R else None\n",
    "        if candidate in vocab:\n",
    "            return candidate\n",
    "    # All words generated by swapping two characters in word\n",
    "    for L, R in splits:\n",
    "        candidate = L + R[1:] if R else None\n",
    "        if candidate in vocab:\n",
    "            return candidate\n",
    "    # All words generated by swapping two characters in word\n",
    "    for L, R in splits:    \n",
    "        candidate = L + R[1] + R[0] + R[2:] if len(R) > 1 else None\n",
    "        if candidate in vocab:\n",
    "            return candidate\n",
    "    # All words generated by inserting a character in word\n",
    "    for L, R in splits:\n",
    "        for c in ascii_vocab:    \n",
    "            candidate = L + c + R \n",
    "            if candidate in vocab:\n",
    "                return candidate\n",
    "    # All words generated by replacing a character in word\n",
    "    for L, R, in splits:\n",
    "        for c in ascii_vocab:    \n",
    "            candidate = L + c +R[1:] if R else None\n",
    "            if candidate in vocab:\n",
    "                return candidate\n",
    "        \n",
    "    return word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "31192 OOV tokens before processing\n",
      "2442 OOV tokens after converting to lower case\n",
      "2310 OOV tokens after converting urls\n",
      "1066 OOV tokens after spelling correction\n",
      "\n",
      "Dev set:\n",
      "4362 OOV tokens before processing\n",
      "463 OOV tokens after converting to lower case\n",
      "424 OOV tokens after converting urls\n",
      "215 OOV tokens after spelling correction\n",
      "\n",
      "Test set:\n",
      "4589 OOV tokens before processing\n",
      "522 OOV tokens after converting to lower case\n",
      "483 OOV tokens after converting urls\n",
      "267 OOV tokens after spelling correction\n",
      "Wall time: 8.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Training set:\")\n",
    "train_sentences = allign_to_vocab(embeddings, train_sentences)\n",
    "\n",
    "print(\"\\nDev set:\")\n",
    "dev_sentences = allign_to_vocab(embeddings, dev_sentences)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "test_sentences = allign_to_vocab(embeddings, test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the data\n",
    "I will encode the targets and the tokens as integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "First build a map from pos tag to an index. Reserve 0 for Padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tag_index = {}\n",
    "for i, pos in enumerate(pos_tags):\n",
    "    pos_tag_index[pos] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = [torch.from_numpy(np.asarray([pos_tag_index[pos] for pos in sentence])).long()  for sentence in train_labels]\n",
    "Y_dev = [torch.from_numpy(np.asarray([pos_tag_index[pos] for pos in sentence])).long()  for sentence in dev_labels]\n",
    "Y_test = [torch.from_numpy(np.asarray([pos_tag_index[pos] for pos in sentence])).long()  for sentence in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens\n",
    "I already built the mapping from token to index. I also replaced all OOV tokens with `unk`, so all words will be in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [torch.from_numpy(np.asarray([token_index[tok] for tok in sentence])).long() for sentence in train_sentences]\n",
    "X_dev = [torch.from_numpy(np.asarray([token_index[tok]  for tok in sentence])).long()  for sentence in dev_sentences]\n",
    "X_test = [torch.from_numpy(np.asarray([token_index[tok] for tok in sentence])).long()  for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PaddedGenerator():\n",
    "    def __init__(self, x_set, y_set = None, batch_size = 126):\n",
    "        \n",
    "        if y_set:\n",
    "            self.has_label = True\n",
    "        else:\n",
    "            self.has_label = False\n",
    "            \n",
    "        self.batch_size = batch_size\n",
    "        if self.has_label:\n",
    "            self.x, self.y, self.sequence_lengths = [], [], []\n",
    "        else:\n",
    "            self.x, self.sequence_lengths = [], []\n",
    "        # Pad Data so all batches have sequences of equal length\n",
    "        for idx in range(int(np.ceil(len(x_set) / float(self.batch_size)))):\n",
    "            batch_x = x_set[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            \n",
    "            # The input is sorted so the first sequence is the longest\n",
    "            max_len = len(batch_x[0])\n",
    "            batch_sequence_lengths = torch.Tensor(list(map(len, batch_x))).int()\n",
    "            batch_x = nn.utils.rnn.pad_sequence(batch_x, batch_first=True)\n",
    "            \n",
    "            self.x.append(batch_x)\n",
    "            self.sequence_lengths.append(batch_sequence_lengths)\n",
    "            \n",
    "            if self.has_label:\n",
    "                batch_y = y_set[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "                batch_y = nn.utils.rnn.pad_sequence(batch_y, batch_first=True)\n",
    "                self.y.append(batch_y)\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.has_label:\n",
    "            return self.x[idx], self.y[idx], self.sequence_lengths[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.sequence_lengths[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I sort the sequences according to length, and then dicide them in bataches where they are padded to be of equal length within the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sorted(X_train, reverse=True, key=len)\n",
    "Y_train = sorted(Y_train, reverse=True, key=len)\n",
    "\n",
    "X_dev = sorted(X_dev, reverse=True, key=len)\n",
    "Y_dev = sorted(Y_dev, reverse=True, key=len)\n",
    "\n",
    "X_test = sorted(X_test, reverse=True, key=len)\n",
    "Y_test = sorted(Y_test, reverse=True, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_padded = PaddedGenerator(X_train, Y_train, batch_size=126)\n",
    "dev_padded = PaddedGenerator(X_dev, Y_dev, batch_size=126)\n",
    "test_padded = PaddedGenerator(X_test, batch_size=126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer\n",
    "Create a frozen embedding layer from the Glove data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dims = 100\n",
    "embedding_matrix = torch.from_numpy(np.array(list(embeddings.values())))\n",
    "n_words = len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a frozen embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embeddings(weights, frozen=True):\n",
    "    \n",
    "    embedding_layer = nn.Embedding(*weights.shape, _weight=embedding_matrix)\n",
    "    embedding_layer.weight.requires_grad = frozen\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = create_embeddings(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLSTM 1\n",
    "Let's implement the BLSTM introduced by Graves, with our Glove embeddings as the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BLSTM1(nn.Module):\n",
    "    def __init__(self, lstm_dim, n_classes, embedding_weights):\n",
    "        super(BLSTM1, self).__init__()\n",
    "        \n",
    "        # Variables\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.vocab_size, self.embedding_dim = embedding_weights.shape\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = create_embeddings(embedding_weights)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, lstm_dim, batch_first=True, bidirectional=True)\n",
    "        self.output = nn.Linear(self.lstm_dim * 2, self.n_classes + 1)\n",
    "        \n",
    "    def forward(self, padded_batch, sequence_lengths):\n",
    "        \n",
    "        # Embeddings\n",
    "        embedded = self.embedding(padded_batch)#.unsqueeze(0)\n",
    "        \n",
    "         # Pack Padded Batch\n",
    "        total_length = padded_batch.size(1)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, batch_first=True, lengths=sequence_lengths)\n",
    "        \n",
    "        # LSTM\n",
    "        out, _ = self.lstm(packed_embedded)\n",
    "        \n",
    "        # Reverse Packing\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True, total_length=total_length)\n",
    "        \n",
    "        # Fully Connected\n",
    "        out = F.log_softmax(self.output(out), 2)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blstm1 = BLSTM1(96, n_labels, embedding_matrix)\n",
    "\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(blstm1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Function inspired by https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "def train_model(model, train_generator, optimizer, criterion, dev_generator=None, epochs = 2):\n",
    "    \n",
    "    # Only enter the validation state if there is a validation_loader\n",
    "    phases = ['train']\n",
    "    data_dict = {'train' : train_generator} \n",
    "    if dev_generator:\n",
    "        phases.append('val')\n",
    "        data_dict['val'] = dev_generator\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in phases:\n",
    "            \n",
    "            data = data_dict[phase]\n",
    "            \n",
    "            # Only update model weights based on the training data\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            words_processed = 0\n",
    "            \n",
    "            for seq, labels, sequence_lengths in tqdm(data, total = len(data)):\n",
    "                \n",
    "                \n",
    "                #labels = torch.autograd.Variable(labels).type(torch.LongTensor)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Only track history during training\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(seq, sequence_lengths)\n",
    "                    loss = criterion(outputs.view(-1, n_labels + 1), labels.view(-1))\n",
    "                    predictions = torch.argmax(outputs, dim=2)\n",
    "                    \n",
    "                    # Only perform backpropagation during training\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                # Save statistics\n",
    "                running_loss += loss.item() * torch.sum(sequence_lengths).item()\n",
    "                # Only count correct classifications when the label is not padding\n",
    "                running_corrects += torch.sum((predictions == labels.data) * (labels.data != 0))\n",
    "                words_processed += torch.sum(sequence_lengths)\n",
    "                \n",
    "                #return predictions, labels, words_processed\n",
    "                \n",
    "            epoch_loss = running_loss / words_processed.item()\n",
    "            epoch_acc = running_corrects.item() / words_processed.item()\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:22<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.9682 Acc: 0.4418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.2596 Acc: 0.3310\n",
      "Epoch 2/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7649 Acc: 0.7754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5118 Acc: 0.8401\n"
     ]
    }
   ],
   "source": [
    "train_model(blstm1, train_padded, optimizer, criterion, dev_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3798 Acc: 0.8869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4255 Acc: 0.8665\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:28<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2907 Acc: 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3846 Acc: 0.8813\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:06<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2355 Acc: 0.9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3750 Acc: 0.8860\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:08<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1992 Acc: 0.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3761 Acc: 0.8892\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:09<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1728 Acc: 0.9489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3810 Acc: 0.8915\n"
     ]
    }
   ],
   "source": [
    "train_model(blstm1, train_padded, optimizer, criterion, dev_padded, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1524 Acc: 0.9552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3856 Acc: 0.8940\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:22<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1358 Acc: 0.9602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3891 Acc: 0.8957\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:30<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1219 Acc: 0.9643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3921 Acc: 0.8978\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1101 Acc: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3951 Acc: 0.8990\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:24<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0998 Acc: 0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3992 Acc: 0.8999\n"
     ]
    }
   ],
   "source": [
    "train_model(blstm1, train_padded, optimizer, criterion, dev_padded, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(blstm1.state_dict(), 'pytorch_models/blstm1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar results as my last BLSTM with a validation accuracy around 90%. Training accuracy is 97% though, so the network is clearly overfitting.\n",
    "\n",
    "It would be interesting to try using a GRU instead of LSTM, apply some regularization like Dropout, and perhaps experiment with character level features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLSTM Two\n",
    "Let's start by adding some regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BLSTM2(nn.Module):\n",
    "    def __init__(self, lstm_dim, n_classes, embedding_weights, dropout_p=0.0):\n",
    "        super(BLSTM2, self).__init__()\n",
    "        \n",
    "        # Variables\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.vocab_size, self.embedding_dim = embedding_weights.shape\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = create_embeddings(embedding_weights)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, lstm_dim, batch_first=True, bidirectional=True)\n",
    "        self.output = nn.Linear(self.lstm_dim * 2, self.n_classes + 1)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        \n",
    "    def forward(self, padded_batch, sequence_lengths):\n",
    "        \n",
    "        # Embeddings\n",
    "        embedded = self.embedding(padded_batch)\n",
    "        \n",
    "         # Pack Padded Batch\n",
    "        total_length = padded_batch.size(1)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, batch_first=True, lengths=sequence_lengths)\n",
    "        \n",
    "        # LSTM\n",
    "        out, _ = self.lstm(packed_embedded)\n",
    "        \n",
    "        # Reverse Packing\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True, total_length=total_length)\n",
    "        \n",
    "        # Dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Fully Connected\n",
    "        out = F.log_softmax(self.output(out), 2)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blstm2 = BLSTM2(96, n_labels, embedding_matrix, dropout_p=.5)\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(blstm2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.2492 Acc: 0.3145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 3.0377 Acc: 0.3035\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3714 Acc: 0.6114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.8420 Acc: 0.7279\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7062 Acc: 0.7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5918 Acc: 0.8121\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5078 Acc: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4728 Acc: 0.8471\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3893 Acc: 0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4114 Acc: 0.8677\n"
     ]
    }
   ],
   "source": [
    "train_model(blstm2, train_padded, optimizer, criterion, dev_padded, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3135 Acc: 0.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3919 Acc: 0.8768\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:41<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2641 Acc: 0.9202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3763 Acc: 0.8843\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2278 Acc: 0.9316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3754 Acc: 0.8880\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2025 Acc: 0.9398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3747 Acc: 0.8916\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:32<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1815 Acc: 0.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3760 Acc: 0.8938\n"
     ]
    }
   ],
   "source": [
    "train_model(blstm2, train_padded, optimizer, criterion, dev_padded, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation performance is now closer to training performance, but the network is still overfitting. Let's try reducing the network size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blstm3 = BLSTM2(64, n_labels, embedding_matrix, dropout_p=.5)\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(blstm3.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]\n",
      "  1%|▊                                                                                 | 1/100 [00:03<05:54,  3.58s/it]\n",
      "  2%|█▋                                                                                | 2/100 [00:05<04:06,  2.52s/it]\n",
      "  3%|██▍                                                                               | 3/100 [00:06<03:23,  2.10s/it]\n",
      "  4%|███▎                                                                              | 4/100 [00:07<02:59,  1.87s/it]\n",
      "  5%|████                                                                              | 5/100 [00:08<02:44,  1.73s/it]\n",
      "Exception in thread Thread-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Gustav\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Gustav\\Anaconda3\\lib\\site-packages\\tqdm\\_monitor.py\", line 63, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\Gustav\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:23<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.1062 Acc: 0.4166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.3512 Acc: 0.5328\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:26<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6237 Acc: 0.8310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4174 Acc: 0.8764\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2972 Acc: 0.9208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3768 Acc: 0.8872\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2326 Acc: 0.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3680 Acc: 0.8917\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2004 Acc: 0.9431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3689 Acc: 0.8935\n"
     ]
    }
   ],
   "source": [
    "train_model(blstm3, train_padded, optimizer, criterion, dev_padded, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracy goes up much faster with a thinner network. Hmm?\n",
    "After 5 epochs the train and validation accuracy are the same as they were after 10 with the wider network. \n",
    "\n",
    "Regardless, I feel like it is a problem that validation accuracy stagnates around 90%. Perhaps just using word embeddings as features is not enough to generalise well?\n",
    "\n",
    "Let's try adding character features! I know that prefixes and suffixes of different lengths can be very potent features, so let's add those!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character level features\n",
    "Let's start by adding one hot encoded versions of knows suffixes and prefixes. I think suffixes are the most important, so I'll go with prefixes of length one, and suffixes of length two and three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SuffixVocab():\n",
    "    def __init__(self, sentences, gram_length, threshhold_to_index = 1, suffix=True):\n",
    "        self.gram_length = gram_length\n",
    "        self.gram_counts = {}\n",
    "        self.suffix = suffix\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                if len(word) < gram_length:\n",
    "                    continue\n",
    "                if suffix:\n",
    "                    gram = word[-gram_length:]\n",
    "                else:\n",
    "                    gram = word[:gram_length]\n",
    "                \n",
    "                try:\n",
    "                    self.gram_counts[gram] += 1\n",
    "                except KeyError:\n",
    "                    self.gram_counts[gram] = 1\n",
    "        \n",
    "        self.index_trim_vocab(threshhold_to_index)\n",
    "        \n",
    "        self.build_one_hot_dict()\n",
    "                    \n",
    "    def index_trim_vocab(self, threshhold = 1):\n",
    "        self.gram2index = {}\n",
    "        self.n_grams = 0\n",
    "        for gram, occurences in self.gram_counts.items():\n",
    "            if occurences >= threshhold:\n",
    "                self.gram2index[gram] = self.n_grams\n",
    "                self.n_grams += 1\n",
    "                \n",
    "    def build_one_hot_dict(self):\n",
    "        self.gram2onehot = {}\n",
    "        for gram, index in self.gram2index.items():\n",
    "            \n",
    "            # Build one hot vector\n",
    "            onehot = torch.zeros(self.n_grams, dtype=torch.long)\n",
    "            onehot[index] = 1.\n",
    "            \n",
    "            self.gram2onehot[gram] = onehot\n",
    "    \n",
    "    def word2onehot(self, word):\n",
    "        if len(word) < self.gram_length:\n",
    "            return torch.zeros(self.n_grams, dtype=torch.long)\n",
    "        \n",
    "        try:\n",
    "            if self.suffix:\n",
    "                return self.gram2onehot[word[-self.gram_length:]]\n",
    "            else:\n",
    "                return self.gram2onehot[word[:self.gram_length]]\n",
    "        except KeyError:\n",
    "            return torch.zeros(self.n_grams, dtype=torch.long)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suffixes of length two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffix2 = SuffixVocab(train_sentences, 2, threshhold_to_index=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffix2_df = pd.DataFrame(np.asarray([list(suffix2.gram_counts.keys()), list(suffix2.gram_counts.values())]).T , columns=['suffix', 'count'])\n",
    "suffix2_df['count'] = suffix2_df['count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffix2_df = suffix2_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suffix</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>he</td>\n",
       "      <td>10194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>nd</td>\n",
       "      <td>6416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>to</td>\n",
       "      <td>5415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ng</td>\n",
       "      <td>5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ed</td>\n",
       "      <td>5362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   suffix  count\n",
       "7      he  10194\n",
       "63     nd   6416\n",
       "25     to   5415\n",
       "17     ng   5400\n",
       "3      ed   5362"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(1, 100)\n",
    "y = np.array([(suffix2_df['count'] >= i).sum() for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x2201a025f28>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niUsJQkRE4lKCEBGRuP4/KVZJ7ZcER2sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2201a00dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.plot(x, y)\n",
    "ax = f[0].axes\n",
    "ax.set_ylim([0, None])\n",
    "ax.set_ylabel('suffixes with x or more occurences')\n",
    "ax.set_xlabel('occurences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restrict our vocab to suffixes that occur at least 20 times. This significantly reduces the number of suffixes we track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 suffixes after trimming\n"
     ]
    }
   ],
   "source": [
    "print(\"%d suffixes after trimming\" %suffix2.n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suffixes of length three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffix3 = SuffixVocab(train_sentences, 3, threshhold_to_index=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffix3_df = pd.DataFrame(np.asarray([list(suffix3.gram_counts.keys()), list(suffix3.gram_counts.values())]).T , columns=['suffix', 'count'])\n",
    "suffix3_df['count'] = suffix3_df['count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffix3_df = suffix3_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suffix</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>9082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>and</td>\n",
       "      <td>5335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ing</td>\n",
       "      <td>5039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hat</td>\n",
       "      <td>2487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>you</td>\n",
       "      <td>2156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   suffix  count\n",
       "7     the   9082\n",
       "66    and   5335\n",
       "16    ing   5039\n",
       "28    hat   2487\n",
       "61    you   2156"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(1, 100)\n",
    "y = np.array([(suffix3_df['count'] >= i).sum() for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x22019ebf208>"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22019ecbfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.plot(x, y)\n",
    "ax = f[0].axes\n",
    "ax.set_ylim([0, None])\n",
    "ax.set_ylabel('suffixes with x or more occurences')\n",
    "ax.set_xlabel('occurences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restrict our vocab to suffixes that occur at least 20 times. This significantly reduces the number of suffixes we track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658 suffixes after trimming\n"
     ]
    }
   ],
   "source": [
    "print(\"%d suffixes after trimming\" %suffix3.n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefix of Length Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix2 = SuffixVocab(train_sentences, 2, threshhold_to_index=20, suffix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix2_df = pd.DataFrame(np.asarray([list(prefix2.gram_counts.keys()), list(prefix2.gram_counts.values())]).T , columns=['suffix', 'count'])\n",
    "prefix2_df['count'] = prefix2_df['count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix2_df = prefix2_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suffix</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>th</td>\n",
       "      <td>16781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>an</td>\n",
       "      <td>6583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>to</td>\n",
       "      <td>6041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>in</td>\n",
       "      <td>4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>of</td>\n",
       "      <td>4040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   suffix  count\n",
       "8      th  16781\n",
       "7      an   6583\n",
       "13     to   6041\n",
       "12     in   4882\n",
       "14     of   4040"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(1, 100)\n",
    "y = np.array([(prefix2_df['count'] >= i).sum() for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x2201a179c50>"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYw4OMcZPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2201a175f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.plot(x, y)\n",
    "ax = f[0].axes\n",
    "ax.set_ylim([0, None])\n",
    "ax.set_ylabel('prefixes with x or more occurences')\n",
    "ax.set_xlabel('occurences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restrict our vocab to suffixes that occur at least 20 times. This significantly reduces the number of suffixes we track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243 prefixes after trimming\n"
     ]
    }
   ],
   "source": [
    "print(\"%d prefixes after trimming\" %prefix2.n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ended up with a 1000 new dimensions in my input data. Perhpas I should represent the character level features in another way, such as encoding every character individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data Sets\n",
    "I'll need to feed these new tensors as input to my model as well. I could map word indexes to prefixes and suffixes, but that would not be possible for OOV words, so I will compute them directly on the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences2features(sentences):\n",
    "    return [torch.cat(\n",
    "            [torch.cat([\n",
    "                torch.LongTensor([token_index[tok]]),\n",
    "                prefix2.word2onehot(tok),\n",
    "                suffix2.word2onehot(tok),\n",
    "                suffix3.word2onehot(tok)]\n",
    "            ).unsqueeze(0) for tok in sentence])\n",
    "            for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sentences2features(train_sentences)\n",
    "X_dev = sentences2features(dev_sentences)\n",
    "X_test = sentences2features(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sorted(X_train, reverse=True, key=len)\n",
    "Y_train = sorted(Y_train, reverse=True, key=len)\n",
    "\n",
    "X_dev = sorted(X_dev, reverse=True, key=len)\n",
    "Y_dev = sorted(Y_dev, reverse=True, key=len)\n",
    "\n",
    "X_test = sorted(X_test, reverse=True, key=len)\n",
    "Y_test = sorted(Y_test, reverse=True, key=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce batch size now that we have much larger data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_padded = PaddedGenerator(X_train, Y_train, batch_size=64)\n",
    "dev_padded = PaddedGenerator(X_dev, Y_dev, batch_size=64)\n",
    "test_padded = PaddedGenerator(X_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLSTM with Suffixes and Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BLSTMGrams(nn.Module):\n",
    "    def __init__(self, lstm_dim, n_classes, embedding_weights, gram_features, dropout_p=0.0):\n",
    "        super(BLSTMGrams, self).__init__()\n",
    "        \n",
    "        # Variables\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.vocab_size, self.embedding_dim = embedding_weights.shape\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_p = dropout_p\n",
    "        self.gram_features = gram_features\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = create_embeddings(embedding_weights)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim + self.gram_features, lstm_dim, batch_first=True, bidirectional=True)\n",
    "        self.output = nn.Linear(self.lstm_dim * 2, self.n_classes + 1)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        \n",
    "    def forward(self, padded_batch, sequence_lengths):\n",
    "        \n",
    "        # Embeddings\n",
    "        embedded = self.embedding(padded_batch[:,:,0])\n",
    "        \n",
    "        # One hot encoded grams\n",
    "        grams = padded_batch[:,:,1:].float()\n",
    "        \n",
    "        # Combine embeddings and grams\n",
    "        encoded = torch.cat([embedded, grams], 2)\n",
    "        \n",
    "        \n",
    "         # Pack Padded Batch\n",
    "        total_length = padded_batch.size(1)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(encoded, batch_first=True, lengths=sequence_lengths)\n",
    "        \n",
    "        # LSTM\n",
    "        out, _ = self.lstm(packed_embedded)\n",
    "        \n",
    "        # Reverse Packing\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True, total_length=total_length)\n",
    "        \n",
    "        # Dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Fully Connected\n",
    "        out = F.log_softmax(self.output(out), 2)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gram_features = X_train[0].shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1149"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blstmgrams = BLSTMGrams(64, n_labels, embedding_matrix, gram_features, dropout_p=.5)\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(blstmgrams.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:12<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3488 Acc: 0.6497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6675 Acc: 0.7917\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [03:52<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2507 Acc: 0.9282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3439 Acc: 0.8985\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [03:37<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1746 Acc: 0.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3485 Acc: 0.9014\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:06<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1526 Acc: 0.9544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:03<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3483 Acc: 0.9017\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:08<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1365 Acc: 0.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3428 Acc: 0.9045\n"
     ]
    }
   ],
   "source": [
    "train_model(blstmgrams, train_padded, optimizer, criterion, dev_padded, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:08<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1242 Acc: 0.9623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3514 Acc: 0.9060\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:07<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1138 Acc: 0.9657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3534 Acc: 0.9078\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:05<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1053 Acc: 0.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3561 Acc: 0.9074\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:08<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0982 Acc: 0.9704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:03<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3550 Acc: 0.9094\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:06<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0894 Acc: 0.9734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3672 Acc: 0.9095\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:06<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0833 Acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3748 Acc: 0.9099\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:05<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0771 Acc: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3725 Acc: 0.9112\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:05<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0720 Acc: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3843 Acc: 0.9111\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:05<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0673 Acc: 0.9802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3915 Acc: 0.9111\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [04:05<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0616 Acc: 0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4151 Acc: 0.9106\n"
     ]
    }
   ],
   "source": [
    "train_model(blstmgrams, train_padded, optimizer, criterion, dev_padded, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy now stagnates around 91%! \n",
    "Training is significantly slower though. There is probably a smarter way of combining embeddings and prefix/suffix encodings. It would be nice to explore this more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In `3. Part of Speech Tagging - Second attempt with RNN` I did Part of Speech (POS) tagging with several RNN's. My most successful was inspired by [Wang et al., 2015](https://arxiv.org/pdf/1510.06168.pdf), who used a model originally from [Graves, 2002](https://www.cs.toronto.edu/~graves/preprint.pdf):\n",
    "Two LSTM layers with 93 hidden units, one doing a forward pass of the input and the other a backward pass. \n",
    "\n",
    "I encoded all words using word embeddings trained by [Glove](https://nlp.stanford.edu/projects/glove/). Glove is Stanfords embedding model.\n",
    "\n",
    "In this notebook I will use a similar approach, but this time I will implement my model in PyTorch. Hopefully increased control will help me to learn an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data\n",
    "I will be using the same training data for my tagger as in all my previous notebooks:\n",
    "[Universal Dependencies - English Web Treebank](http://universaldependencies.org/treebanks/en_ewt/index.html), a CoNLL-U formart corpus with 254 830 words and 16 622 sentences in english *taken from various web media including weblogs, newsgroups, emails, reviews, and Yahoo! answers*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "First lets load the training data and convert it to a python dictionary.\n",
    "I use the [conllu](https://github.com/EmilStenstrom/conllu) python package to parse the CoNLL-U files to dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'UD/UD_English-EWT'\n",
    "with open('{}/en_ewt-ud-train.conllu'.format(directory), 'r', encoding='utf-8') as f:\n",
    "    train_text = f.read()\n",
    "    \n",
    "directory = 'UD/UD_English-EWT'\n",
    "with open('{}/en_ewt-ud-dev.conllu'.format(directory), 'r', encoding='utf-8') as f:\n",
    "    dev_text = f.read()\n",
    "    \n",
    "directory = 'UD/UD_English-EWT'\n",
    "with open('{}/en_ewt-ud-test.conllu'.format(directory), 'r', encoding='utf-8') as f:\n",
    "    test_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dict = conllu.parse(train_text)\n",
    "dev_dict = conllu.parse(dev_text)\n",
    "test_dict = conllu.parse(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count sentences and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set contains 12543 sentences and 204607 tokens\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "n_train_sentences = len(train_dict)\n",
    "n_train_tokens = reduce(lambda x, y: x + len(y), train_dict, 0)\n",
    "\n",
    "print(\"The training set contains {} sentences and {} tokens\".format(n_train_sentences, n_train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = [[token['form'] for token in sentence] for sentence in train_dict]\n",
    "train_labels = [[token['upostag'] for token in sentence] for sentence in train_dict]\n",
    "\n",
    "dev_sentences = [[token['form'] for token in sentence] for sentence in dev_dict]\n",
    "dev_labels = [[token['upostag'] for token in sentence] for sentence in dev_dict]\n",
    "\n",
    "test_sentences = [[token['form'] for token in sentence] for sentence in test_dict]\n",
    "test_labels = [[token['upostag'] for token in sentence] for sentence in test_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tags = list(set(reduce(lambda x, y: x + y, train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labels = len(pos_tags)\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "[Wang et al.](https://arxiv.org/pdf/1510.06168.pdf) showed that a bidirectional LSTM network could achieve state of the art performance without using any morphological features, they only used these features:\n",
    "* Word embedding of the word (cast to lower case). Embeddings trained by the same architecture, but on another task.\n",
    "* Suffix of length two, one-hot encoded\n",
    "* Wether the word is all caps, lower case, or has an initial capital letter. One-hot encoded.\n",
    "\n",
    "Other papers, like [Xiao et al.](https://arxiv.org/abs/1809.01997), complement word embeddings with character embeddings. \n",
    "It would be interesting to experiment with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove\n",
    "I will opt to use the 100 dimensional Glove 6B data. My vocabulary will be exactly the words inside the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_path = 'glove/glove.6B/glove.6B.100d.txt'\n",
    "embeddings = {}\n",
    "token_index = {}\n",
    "index_token = {}\n",
    "with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        tok, *vec = line.split()\n",
    "        embeddings[tok] = np.array(vec, dtype='float32')\n",
    "        # Reserve index 0 for padding\n",
    "        token_index[tok] = i + 1\n",
    "        index_token[i+1] = tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know from my last notebook that my data has many words that are OOV for Glove. I adressed this by pre-processing my data. In this notebook I will condense my preprocessing to a single method, check the other one for more rationale on why I apply each step.\n",
    "\n",
    "I will apply pre-processing to all three data sets: train, dev and test. As the preprocessing is not trained on the data this could be done on new data in production as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def allign_to_vocab(vocab, sentences):\n",
    "    \n",
    "    # Find all OOV tokens\n",
    "    oov = find_oov(vocab, sentences)\n",
    "    print(\"%d OOV tokens before processing\" % len(oov))\n",
    "    \n",
    "    # Convert to lower case\n",
    "    sentences = [[token.lower() for token in sentence] for sentence in sentences]\n",
    "    \n",
    "    oov = find_oov(vocab, sentences)\n",
    "    print(\"%d OOV tokens after converting to lower case\" % len(oov))\n",
    "    \n",
    "    # Replace URL's with 'url'\n",
    "    sentences = [[convert_url(token) for token in sentence] for sentence in sentences]\n",
    "    \n",
    "    oov = find_oov(vocab, sentences)\n",
    "    print(\"%d OOV tokens after converting urls\" % len(oov))\n",
    "    \n",
    "    # Build spelling correction dictionary\n",
    "    # Search for word in vocabulary words within 1 Levensthein Damerau distance\n",
    "    new_spelling = dict([(word, find_one_neighbour(word, embeddings)) for word in oov])\n",
    "    sentences = [[new_spelling[token] if token in new_spelling else token for token in sentence] for sentence in sentences]\n",
    "    \n",
    "    oov = find_oov(vocab, sentences)\n",
    "    print(\"%d OOV tokens after spelling correction\" % len(oov))\n",
    "    \n",
    "    # Replace OOV words with 'unk'\n",
    "    # See https://stackoverflow.com/questions/49239941/what-is-unk-in-glove-6b-50d-txt\n",
    "    sentences = [['unk' if token in oov else token for token in sentence] for sentence in sentences]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def find_oov(vocab, sentences):\n",
    "    oov = []\n",
    "    for sentence in sentences:\n",
    "        for tok in sentence:\n",
    "            if tok not in vocab:\n",
    "                oov.append(tok)\n",
    "    return oov\n",
    "     \n",
    "def convert_url(token):\n",
    "    # Match words starting with www., http:// or https://\n",
    "    if re.match(r'^(?:https{0,1}\\:\\/\\/.*|www\\.*)', token):\n",
    "        return \"url\"\n",
    "    else:\n",
    "        return token\n",
    "\n",
    "# Checks for vocabulary words within 1 Damerau Levenstein distance and returns the first match\n",
    "# Logic inspired by http://norvig.com/spell-correct.html\n",
    "def find_one_neighbour(word, vocab):\n",
    "    \n",
    "    ascii_vocab = [str(chr(i)) for i in range(32, 127)]\n",
    "    \n",
    "    # Tuples with all possible splits of word\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    \n",
    "    # All words generated by deleting one character\n",
    "    for L, R in splits:\n",
    "        candidate = L + R[1:] if R else None\n",
    "        if candidate in vocab:\n",
    "            return candidate\n",
    "    # All words generated by swapping two characters in word\n",
    "    for L, R in splits:\n",
    "        candidate = L + R[1:] if R else None\n",
    "        if candidate in vocab:\n",
    "            return candidate\n",
    "    # All words generated by swapping two characters in word\n",
    "    for L, R in splits:    \n",
    "        candidate = L + R[1] + R[0] + R[2:] if len(R) > 1 else None\n",
    "        if candidate in vocab:\n",
    "            return candidate\n",
    "    # All words generated by inserting a character in word\n",
    "    for L, R in splits:\n",
    "        for c in ascii_vocab:    \n",
    "            candidate = L + c + R \n",
    "            if candidate in vocab:\n",
    "                return candidate\n",
    "    # All words generated by replacing a character in word\n",
    "    for L, R, in splits:\n",
    "        for c in ascii_vocab:    \n",
    "            candidate = L + c +R[1:] if R else None\n",
    "            if candidate in vocab:\n",
    "                return candidate\n",
    "        \n",
    "    return word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "31192 OOV tokens before processing\n",
      "2442 OOV tokens after converting to lower case\n",
      "2310 OOV tokens after converting urls\n",
      "1066 OOV tokens after spelling correction\n",
      "\n",
      "Dev set:\n",
      "4362 OOV tokens before processing\n",
      "463 OOV tokens after converting to lower case\n",
      "424 OOV tokens after converting urls\n",
      "215 OOV tokens after spelling correction\n",
      "\n",
      "Test set:\n",
      "4589 OOV tokens before processing\n",
      "522 OOV tokens after converting to lower case\n",
      "483 OOV tokens after converting urls\n",
      "267 OOV tokens after spelling correction\n",
      "Wall time: 8.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Training set:\")\n",
    "train_sentences = allign_to_vocab(embeddings, train_sentences)\n",
    "\n",
    "print(\"\\nDev set:\")\n",
    "dev_sentences = allign_to_vocab(embeddings, dev_sentences)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "test_sentences = allign_to_vocab(embeddings, test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the data\n",
    "I will encode the targets and the tokens as integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "First build a map from pos tag to an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tag_index = {}\n",
    "for i, pos in enumerate(pos_tags):\n",
    "    pos_tag_index[pos] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = [torch.from_numpy(np.asarray([pos_tag_index[pos] for pos in sentence])).long()  for sentence in train_labels]\n",
    "Y_dev = [torch.from_numpy(np.asarray([pos_tag_index[pos] for pos in sentence])).long()  for sentence in dev_labels]\n",
    "Y_test = [torch.from_numpy(np.asarray([pos_tag_index[pos] for pos in sentence])).long()  for sentence in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens\n",
    "I already built the mapping from token to index. I also replaced all OOV tokens with `unk`, so all words will be in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [torch.from_numpy(np.asarray([token_index[tok] for tok in sentence])).long() for sentence in train_sentences]\n",
    "X_dev = [torch.from_numpy(np.asarray([token_index[tok]  for tok in sentence])).long()  for sentence in dev_sentences]\n",
    "X_test = [torch.from_numpy(np.asarray([token_index[tok] for tok in sentence])).long()  for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer\n",
    "Create a frozen embedding layer from the Glove data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dims = 100\n",
    "embedding_matrix = torch.from_numpy(np.array(list(embeddings.values())))\n",
    "n_words = len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a frozen embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400000, 100])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embeddings(weights, frozen=True):\n",
    "    \n",
    "    embedding_layer = nn.Embedding(*weights.shape, _weight=embedding_matrix)\n",
    "    embedding_layer.weight.requires_grad = frozen\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = create_embeddings(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLSTM 1\n",
    "Let's implement the BLSTM introduced by Graves, with our Glove embeddings as the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BLSTM1(nn.Module):\n",
    "    def __init__(self, lstm_dim, n_classes, embedding_weights):\n",
    "        super(BLSTM1, self).__init__()\n",
    "        \n",
    "        # Variables\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.vocab_size, self.embedding_dim = embedding_weights.shape\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = create_embeddings(embedding_weights)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, lstm_dim, batch_first=True, bidirectional=True)\n",
    "        self.output = nn.Linear(self.lstm_dim * 2, self.n_classes)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        \n",
    "        # Embeddings\n",
    "        embedded = self.embedding(sentence).unsqueeze(0)\n",
    "        \n",
    "        # LSTM\n",
    "        out, _ = self.lstm(embedded)\n",
    "        \n",
    "        # Fully Connected\n",
    "        return F.log_softmax(self.output(out), 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm1 = BLSTM1(96, n_labels, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(blstm1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Function inspired by https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "def train_model(model, X_train, y_train, optimizer, criterion, X_dev = None, y_dev = None, epochs = 2):\n",
    "    \n",
    "    # Only enter the validation state if there is a validation_loader\n",
    "    phases = ['train']\n",
    "    data_dict = {'train' : list(zip(X_train, y_train))} \n",
    "    if X_dev and y_dev:\n",
    "        phases.append('val')\n",
    "        data_dict['val'] = list(zip(X_dev, y_dev))\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in phases:\n",
    "            \n",
    "            data = data_dict[phase]\n",
    "            \n",
    "            # Only update model weights based on the training data\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for seq, labels in tqdm(data, total = len(data)):\n",
    "                \n",
    "                #labels = torch.autograd.Variable(labels).type(torch.LongTensor)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Only track history during training\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(seq).squeeze(0)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    predictions = torch.argmax(outputs, dim=1)\n",
    "                    \n",
    "                    # Only perform backpropagation during training\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                # Save statistics\n",
    "                running_loss += loss.item() * seq.size(0)\n",
    "                running_corrects += torch.sum(predictions == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(data)\n",
    "            epoch_acc = running_corrects.double() / len(data)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 27.4362 Acc: 12.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 39.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 27.4377 Acc: 9.7000\n",
      "Epoch 2/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 24.7206 Acc: 15.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 37.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 26.2986 Acc: 10.0000\n"
     ]
    }
   ],
   "source": [
    "train_model(blstm1, X_train[:10], Y_train[:10], optimizer, criterion, X_dev[:10], Y_dev[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so I constructed my model and training function. Unfortunately training is very slow now that I am processing just one sentence at a time. Maybe I should consider introducing padding to allow batch processing?\n",
    "\n",
    "I'll continue tomorrow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

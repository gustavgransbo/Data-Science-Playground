{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In my previous notebook `2. Text Processing` I tokenized and stemmed the bodies and subjects of 6041 emails from the Spamassassin corpus. \n",
    "\n",
    "Eventually I will represent emails as one-hot vectors, with every vector representing a word in the vocabulary. Currently this would lead to a 98401-dimensional space.\n",
    "\n",
    "In this notebook I will implement Principal Component Analysis, PCA, and use it for dimensionality reduction on my data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing PCA\n",
    "I will start of by implementing PCA using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementation using numpys single value decomposition\n",
    "class PCA_svd():\n",
    "    def transform(self, X, dims):\n",
    "        X = X - X.mean(axis=0)\n",
    "        _, _, V = np.linalg.svd(X - X.mean(axis=0))\n",
    "        V_dims = V[:dims]\n",
    "        return X.dot(V_dims.T)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementations using correlation matrix\n",
    "class PCA():\n",
    "    def fit(self, X):\n",
    "        self._mean = X.mean(axis=0)\n",
    "        X = X - self._mean\n",
    "        X_cov = np.cov(X.T)\n",
    "        eig_vals, eig_vecs = np.linalg.eig(X_cov)\n",
    "        sort_index = eig_vals.argsort()[::-1]\n",
    "        self.eig_vecs = eig_vecs[:,sort_index]\n",
    "        eig_vals = eig_vals[sort_index]\n",
    "        self.information = eig_vals/eig_vals.sum()\n",
    "        \n",
    "    def transform(self, X, dim=None):\n",
    "        X = X - self._mean\n",
    "        if not dim:\n",
    "            dim = len(self.eig_vecs)\n",
    "        \n",
    "        # If dim is set to a ratio, then find out how many dimensions are required to keep that ratio of information\n",
    "        if 0 <= dim < 1:\n",
    "            dim = np.argmax(np.cumsum(self.information) > dim)+1\n",
    "        return X.dot(self.eig_vecs[:,:dim])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out or implementation by comparing with the the svd implementation and sklearns PCA implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [1,3], [1,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 3],\n",
       "       [1, 5]])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  3.33333333])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk_pca = sklearnPCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.33333333,  0.        ],\n",
       "       [-0.33333333, -0.        ],\n",
       "       [ 1.66666667,  0.        ]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.33333333,  0.        ],\n",
       "       [-0.33333333,  0.        ],\n",
       "       [ 1.66666667,  0.        ]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.transform(X, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_svd = PCA_svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.33333333,  0.        ],\n",
       "       [-0.33333333,  0.        ],\n",
       "       [ 1.66666667,  0.        ]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_svd.transform(X, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent results for our toy matrix. \n",
    "\n",
    "Let's test on a random vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = rand(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_pca.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58966147,  0.86115239,  0.96129762,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(pca.information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58966147,  0.86115239,  0.96129762,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(sk_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -6.76584967e-01,  -2.49731314e-01,   2.07600396e-01,\n",
       "         -3.56303579e-02,   3.73283151e-16],\n",
       "       [  5.09866145e-01,   3.27248632e-01,   2.13156614e-01,\n",
       "         -8.35043113e-02,  -1.64549378e-17],\n",
       "       [ -2.62786138e-01,   1.86974737e-01,  -2.92669806e-01,\n",
       "         -1.19341722e-01,   4.12900884e-16],\n",
       "       [ -1.04531497e-01,   2.27751301e-01,  -3.64434736e-02,\n",
       "          2.19627966e-01,   1.39547410e-16],\n",
       "       [  5.34036456e-01,  -4.92243356e-01,  -9.16437310e-02,\n",
       "          1.88484256e-02,  -1.88742647e-16]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pca = pca.transform(Y)\n",
    "Y_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.76584967e-01,   2.49731314e-01,  -2.07600396e-01,\n",
       "         -3.56303579e-02,   2.01316271e-16],\n",
       "       [ -5.09866145e-01,  -3.27248632e-01,  -2.13156614e-01,\n",
       "         -8.35043113e-02,   5.17459270e-17],\n",
       "       [  2.62786138e-01,  -1.86974737e-01,   2.92669806e-01,\n",
       "         -1.19341722e-01,   1.47615485e-16],\n",
       "       [  1.04531497e-01,  -2.27751301e-01,   3.64434736e-02,\n",
       "          2.19627966e-01,   2.97259318e-16],\n",
       "       [ -5.34036456e-01,   4.92243356e-01,   9.16437310e-02,\n",
       "          1.88484256e-02,  -2.55663004e-18]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_sk_pca = sk_pca.transform(Y)\n",
    "Y_sk_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dimensions have opposite directions, but this does not matter. All I need is for the principal components to be parallel!\n",
    "\n",
    "Now let's move on with the project, time to do some dimensionality reduction on the email data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction on the email word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

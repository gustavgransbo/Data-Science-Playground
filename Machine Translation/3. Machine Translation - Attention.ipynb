{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook I will attempt to use attention for machine translation.\n",
    "Just like in previous notebooks I am very much inspired by Francois Chollet's article [A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html). \n",
    "\n",
    "In this notebook I am using a [forked version of keras](https://github.com/gustavgransbo/keras/releases/tag/2.2.1) that merges Anders Huss [Pull Request #8296](https://github.com/keras-team/keras/pull/8296) which implements support for reccurent attention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "I will be using data from the same source as Chollet, http://www.manythings.org/anki/. I'm using the 17303 sentence long swe-eng data set, that contains english sentences and their swedish translations. The french data set used by Chollet is much larger, but he limited his training set to 10 000 sentences and used 20% of it for validation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/swe-eng/swe.txt'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_sentences, target_sentences = [], []\n",
    "for line in lines:\n",
    "    try:\n",
    "        input_text, target_text, *_ = line.split('\\t')\n",
    "    except ValueError:\n",
    "        print(line)\n",
    "        \n",
    "    # Chollet uses tab as start of sentence and line feed as end of sentence characters.\n",
    "    # The start of sentence character will be used to seed new sentences and the end\n",
    "    # of sentence character will be used to terminate sentences.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_sentences.append(input_text)\n",
    "    target_sentences.append(target_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate sentence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_lens = np.array([len(sentence) for sentence in input_sentences])\n",
    "target_seq_lens = np.array([len(sentence) for sentence in target_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " input_idx = np.where(input_seq_lens <= max_seq_len)\n",
    " target_idx = np.where(target_seq_lens <= max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16741 input sentences with 50 or fewer characters\n",
      "16522 target sentences with 50 or fewer characters\n"
     ]
    }
   ],
   "source": [
    "print(\"{} input sentences with {} or fewer characters\".format(len(input_idx[0]), max_seq_len))\n",
    "print(\"{} target sentences with {} or fewer characters\".format(len(target_idx[0]), max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_idx = np.intersect1d(input_idx, target_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16404 input sentence pairs with 50 or fewer characters in both languages\n"
     ]
    }
   ],
   "source": [
    "print(\"{} input sentence pairs with {} or fewer characters in both languages\".format(len(keep_idx), max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = np.array(input_sentences)[keep_idx]\n",
    "target_sentences = np.array(target_sentences)[keep_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = set()\n",
    "target_characters = set()\n",
    "for input_text, target_text in zip(input_sentences, target_sentences):\n",
    "    for char in input_text:\n",
    "        input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        target_characters.add(char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "\n",
    "input_vocab_size = len(input_characters)\n",
    "target_vocab_size = len(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size: 75\n",
      "Target vocab size: 79\n"
     ]
    }
   ],
   "source": [
    "print(\"Input vocab size: {}\".format(input_vocab_size))\n",
    "print(\"Target vocab size: {}\".format(target_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build padded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create completely empty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_sentences), max_seq_len, input_vocab_size),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_sentences), max_seq_len, target_vocab_size),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_sentences), max_seq_len, target_vocab_size),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16404, 50, 75)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16404, 50, 79)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16404, 50, 79)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fill in all the values that we have available, leaving the rest as padding. Encode all characters using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_sentences, target_sentences)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data into a training and a validation set\n",
    "I will use 8 000 sentances as training set and 2000 as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainig_size, validation_size = 8000, 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = np.random.permutation(len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = shuffle_idx[:trainig_size], shuffle_idx[trainig_size:trainig_size+validation_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train, encoder_input_val = encoder_input_data[train_idx], encoder_input_data[val_idx]\n",
    "\n",
    "decoder_input_train, decoder_input_val = decoder_input_data[train_idx], decoder_input_data[val_idx]\n",
    "\n",
    "decoder_target_train, decoder_target_val = decoder_target_data[train_idx], decoder_target_data[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple model. Anders Huss proposes this one in the attention source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTMCell, RNN, TimeDistributed, Dense\n",
    "from keras import Model, Input\n",
    "from keras.layers.attention import MixtureOfGaussian1DAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_english = Input((None, input_vocab_size))\n",
    "target_french_tm1 = Input((None, target_vocab_size))\n",
    "cell = MixtureOfGaussian1DAttention(LSTMCell(64), components=3, heads=3)\n",
    "attention_lstm = RNN(cell, return_sequences=True)\n",
    "h_sequence = attention_lstm(target_french_tm1, constants=input_english)\n",
    "output_layer = TimeDistributed(Dense(target_vocab_size, activation='softmax'))\n",
    "predicted_french = output_layer(h_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = Model(\n",
    "            inputs=[target_french_tm1, input_english],\n",
    "            outputs=predicted_french\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 50)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_train.any(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights_train = decoder_target_train.any(2).astype(int)\n",
    "sample_weights_val = decoder_target_val.any(2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/2\n",
      "8000/8000 [==============================] - 316s 40ms/step - loss: 3.1340 - weighted_acc: 0.1626 - val_loss: 2.9880 - val_weighted_acc: 0.1746\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 307s 38ms/step - loss: 2.8945 - weighted_acc: 0.2060 - val_loss: 2.8085 - val_weighted_acc: 0.2383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22405d01908>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.compile(optimizer='Adam', loss='categorical_crossentropy', sample_weight_mode='temporal', weighted_metrics=['accuracy'])\n",
    "train_model.fit(\n",
    "    x=[decoder_input_train, encoder_input_train],\n",
    "    y=decoder_target_train,\n",
    "    sample_weight = sample_weights_train,\n",
    "    epochs=2,\n",
    "    batch_size = 64,\n",
    "    validation_data = ([decoder_input_val, encoder_input_val], decoder_target_val, sample_weights_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, target_vocab_size))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    all_predictions = []\n",
    "    while not stop_condition:\n",
    "        output_tokens = train_model.predict([target_seq, input_seq])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        #all_predictions.append((target_seq, \"\".join([reverse_target_char_index[i] for i in output_tokens.argmax(2).flatten()])))\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        next_target = np.zeros((1, target_seq.shape[1] + 1, target_vocab_size))\n",
    "        next_target[0,:-1,:] = target_seq\n",
    "        next_target[0, -1, sampled_token_index] = 1.\n",
    "        target_seq = next_target\n",
    "        \n",
    "\n",
    "    return decoded_sentence#, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences_val = input_sentences[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I'll go in a minute.\n",
      "Decoded sentence: JJJJJJJJaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input sentence: I said Tom is a friend.\n",
      "Decoded sentence: JJJJJaaaaaaaaaaaaaaaaaaaa a a a  a a a a a  a a a  \n",
      "-\n",
      "Input sentence: I never saw you.\n",
      "Decoded sentence: JJJJJJaaaaaaaaaaaaaaaaaaaaaa  a a a a a a a aa a a \n",
      "-\n",
      "Input sentence: I feel like playing, too.\n",
      "Decoded sentence: JJJJJJJaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa    \n",
      "-\n",
      "Input sentence: Tom drives.\n",
      "Decoded sentence: ooooooooooooooooooo o o o           o o     aa a   \n",
      "-\n",
      "Input sentence: Tom's lucky.\n",
      "Decoded sentence: oooooooooooooooo o o  o       o  o o o      a  a   \n",
      "-\n",
      "Input sentence: How about a contest?\n",
      "Decoded sentence: aaaaaaaaaaaaaaa a a a a a a a a a a  a  a a  a  a  \n",
      "-\n",
      "Input sentence: I can help you out.\n",
      "Decoded sentence: JJJJJaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input sentence: I can't remember the lyrics.\n",
      "Decoded sentence: JJJJJaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa    a  a \n",
      "-\n",
      "Input sentence: Keep dancing.\n",
      "Decoded sentence: aaaaaaaaaaaaaaaaaaaaaaaaaaa a aa a aa a aa a aa aa \n",
      "-\n",
      "Input sentence: I'll bring Tom.\n",
      "Decoded sentence: JJJJJJJaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: aaaaaaaaaaaaaaaaa a  a a a a a a a a a a a a  a a  \n",
      "-\n",
      "Input sentence: We can both do it.\n",
      "Decoded sentence: Vaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa a a a a aa a \n",
      "-\n",
      "Input sentence: Who are Tom's friends?\n",
      "Decoded sentence: VVVaaaaaaaaaaaa a a a a aa a a a a  a a a  a  a a  \n",
      "-\n",
      "Input sentence: That doesn't surprise me.\n",
      "Decoded sentence: ooooooaaaaaaaa a a aa  a a a a  a a  a a  a  a a  a\n",
      "-\n",
      "Input sentence: What do you need to know?\n",
      "Decoded sentence: VVaaaaaaaaaaaaaaaa a a a a a a  a a a  a a  a a a  \n",
      "-\n",
      "Input sentence: The earth is smaller than the sun.\n",
      "Decoded sentence: oooooooooaaaaaaaaaaaaaaa aa a aa a a  a a      a  a\n",
      "-\n",
      "Input sentence: Tom hates liars.\n",
      "Decoded sentence: ooooooooooooooo o o  o   o  o  o  o o o  aaaa aaa  \n",
      "-\n",
      "Input sentence: Who received it?\n",
      "Decoded sentence: VVVaaaaaaaaaaa a a aa a a a a a a a a a a   a  a  a\n",
      "-\n",
      "Input sentence: He was devastated.\n",
      "Decoded sentence: aaaaaaaaaaaaaaaaaaaaaaaaa a a aa a a aa a a a a  a \n",
      "-\n",
      "Input sentence: Tom is multilingual.\n",
      "Decoded sentence: oooooooooooooooooo o o o  o      o  o o o o      a \n",
      "-\n",
      "Input sentence: Have a nice day.\n",
      "Decoded sentence: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input sentence: I'll go ask Tom.\n",
      "Decoded sentence: JJJJJJJJaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input sentence: I'll meet you back on the ship.\n",
      "Decoded sentence: JJJJJJJJaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input sentence: Tom can't decide what to buy.\n",
      "Decoded sentence: oooooooooooooo o o o   o   o  oaaaaaaa a a aa a a  \n",
      "-\n",
      "Input sentence: Tom looked at the floor.\n",
      "Decoded sentence: oooooooooooooooooo o o o o  o   o  o o o  o oo o   \n",
      "-\n",
      "Input sentence: I think that's a hoax.\n",
      "Decoded sentence: JJJJJJaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input sentence: I was quite hungry\n",
      "Decoded sentence: JJJJJJaaaaaaaaaaaaaaaaaaaaaaaaaaa    a a a a a aa a\n",
      "-\n",
      "Input sentence: I just bought this.\n",
      "Decoded sentence: JJJJJJaaaaaaaaaaaaaaaaa a  a a a a a a  a a a a a a\n",
      "-\n",
      "Input sentence: Do you miss it?\n",
      "Decoded sentence: aaaaaaaaaa a a a a  a a         a a a            a \n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(30):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_val[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_sentences_val[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/2\n",
      "8000/8000 [==============================] - 287s 36ms/step - loss: 2.3738 - weighted_acc: 0.3474 - val_loss: 2.3250 - val_weighted_acc: 0.3617\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 288s 36ms/step - loss: 2.2742 - weighted_acc: 0.3705 - val_loss: 2.2367 - val_weighted_acc: 0.3839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22406e6fb70>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.fit(\n",
    "    x=[decoder_input_train, encoder_input_train],\n",
    "    y=decoder_target_train,\n",
    "    sample_weight = sample_weights_train,\n",
    "    epochs=2,\n",
    "    batch_size = 64,\n",
    "    validation_data = ([decoder_input_val, encoder_input_val], decoder_target_val, sample_weights_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gustav\\Anaconda3\\envs\\keras-attention\\lib\\site-packages\\keras\\engine\\network.py:889: UserWarning: Layer rnn_4 was passed non-serializable keyword arguments: {'constants': [<tf.Tensor 'input_7:0' shape=(?, ?, 75) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "train_model.save('keras_models/attention_simple.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I'll go in a minute.\n",
      "Decoded sentence: Jag äar ha me mi mit de de.\n",
      "\n",
      "-\n",
      "Input sentence: I said Tom is a friend.\n",
      "Decoded sentence: Jag hr dom Tom mr hr hr hr.\n",
      "\n",
      "-\n",
      "Input sentence: I never saw you.\n",
      "Decoded sentence: Jag har var va da d.\n",
      "\n",
      "-\n",
      "Input sentence: I feel like playing, too.\n",
      "Decoded sentence: Jag har ka ke de de de kig meg.\n",
      "\n",
      "-\n",
      "Input sentence: Tom drives.\n",
      "Decoded sentence: Tom hrr hor.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's lucky.\n",
      "Decoded sentence: Tom är kar ka.\n",
      "\n",
      "-\n",
      "Input sentence: How about a contest?\n",
      "Decoded sentence: Hur ka da da ka ket?\n",
      "\n",
      "-\n",
      "Input sentence: I can help you out.\n",
      "Decoded sentence: Jag kan han pa du du de de de.\n",
      "\n",
      "-\n",
      "Input sentence: I can't remember the lyrics.\n",
      "Decoded sentence: Jag kan iit mim mit mr mr kr kr.\n",
      "\n",
      "-\n",
      "Input sentence: Keep dancing.\n",
      "Decoded sentence: Hin dennn.\n",
      "\n",
      "-\n",
      "Input sentence: I'll bring Tom.\n",
      "Decoded sentence: Jag är kr hot momomom.\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Van kom.\n",
      "\n",
      "-\n",
      "Input sentence: We can both do it.\n",
      "Decoded sentence: Vi kan kat de de de de de.\n",
      "\n",
      "-\n",
      "Input sentence: Who are Tom's friends?\n",
      "Decoded sentence: Var hr mom mr mr srr \n",
      "\n",
      "-\n",
      "Input sentence: That doesn't surprise me.\n",
      "Decoded sentence: Det de dr sir srr srr sär sär.\n",
      "\n",
      "-\n",
      "Input sentence: What do you need to know?\n",
      "Decoded sentence: Vad da du de de de de de?\n",
      "\n",
      "-\n",
      "Input sentence: The earth is smaller than the sun.\n",
      "Decoded sentence: De har hr hr har har hat hat hn hr hnn.\n",
      "\n",
      "-\n",
      "Input sentence: Tom hates liars.\n",
      "Decoded sentence: Tom hr sar sar.\n",
      "\n",
      "-\n",
      "Input sentence: Who received it?\n",
      "Decoded sentence: Var kr kit de?\n",
      "\n",
      "-\n",
      "Input sentence: He was devastated.\n",
      "Decoded sentence: Han var dat datat.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is multilingual.\n",
      "Decoded sentence: Tom är mit mit mil.\n",
      "\n",
      "-\n",
      "Input sentence: Have a nice day.\n",
      "Decoded sentence: Ha n na kan da da da.\n",
      "\n",
      "-\n",
      "Input sentence: I'll go ask Tom.\n",
      "Decoded sentence: Jag äar ha ma momoTT.\n",
      "\n",
      "-\n",
      "Input sentence: I'll meet you back on the ship.\n",
      "Decoded sentence: Jag är mat de de da ka ka ka he hr het.\n",
      "\n",
      "-\n",
      "Input sentence: Tom can't decide what to buy.\n",
      "Decoded sentence: Tom kan iit de de de de de de de de \n",
      "\n",
      "-\n",
      "Input sentence: Tom looked at the floor.\n",
      "Decoded sentence: Tom mote de de de de kr de.\n",
      "\n",
      "-\n",
      "Input sentence: I think that's a hoax.\n",
      "Decoded sentence: Jag hr hr det da ha ha ha \n",
      "\n",
      "-\n",
      "Input sentence: I was quite hungry\n",
      "Decoded sentence: Jag var da dr digargggggggggg\n",
      "\n",
      "-\n",
      "Input sentence: I just bought this.\n",
      "Decoded sentence: Jag har de de det det det.\n",
      "\n",
      "-\n",
      "Input sentence: Do you miss it?\n",
      "Decoded sentence: Har du di me ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(30):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_val[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_sentences_val[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.ModelCheckpoint at 0x22406e92e80>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelCheckpoint(\"keras_models/attention_simple_best.h5\", monitor='val_weighted_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 268s 33ms/step - loss: 2.0802 - weighted_acc: 0.4132 - val_loss: 2.0454 - val_weighted_acc: 0.4206\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gustav\\Anaconda3\\envs\\keras-attention\\lib\\site-packages\\keras\\engine\\network.py:889: UserWarning: Layer rnn_4 was passed non-serializable keyword arguments: {'constants': [<tf.Tensor 'input_7:0' shape=(?, ?, 75) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 300s 38ms/step - loss: 2.0096 - weighted_acc: 0.4274 - val_loss: 1.9832 - val_weighted_acc: 0.4350\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.9516 - weighted_acc: 0.4384 - val_loss: 1.9301 - val_weighted_acc: 0.4435\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 298s 37ms/step - loss: 1.9027 - weighted_acc: 0.4486 - val_loss: 1.8869 - val_weighted_acc: 0.4577\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.8611 - weighted_acc: 0.4590 - val_loss: 1.8505 - val_weighted_acc: 0.4659\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.8279 - weighted_acc: 0.4668 - val_loss: 1.8198 - val_weighted_acc: 0.4710\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 293s 37ms/step - loss: 1.7982 - weighted_acc: 0.4751 - val_loss: 1.7957 - val_weighted_acc: 0.4780\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 299s 37ms/step - loss: 1.7744 - weighted_acc: 0.4806 - val_loss: 1.7698 - val_weighted_acc: 0.4871\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 293s 37ms/step - loss: 1.7494 - weighted_acc: 0.4885 - val_loss: 1.7503 - val_weighted_acc: 0.4903\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.7287 - weighted_acc: 0.4932 - val_loss: 1.7312 - val_weighted_acc: 0.4948\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 293s 37ms/step - loss: 1.7100 - weighted_acc: 0.4991 - val_loss: 1.7176 - val_weighted_acc: 0.4975\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.6924 - weighted_acc: 0.5036 - val_loss: 1.7033 - val_weighted_acc: 0.5040\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.6779 - weighted_acc: 0.5080 - val_loss: 1.6878 - val_weighted_acc: 0.5092\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.6603 - weighted_acc: 0.5126 - val_loss: 1.6745 - val_weighted_acc: 0.5134\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 293s 37ms/step - loss: 1.6472 - weighted_acc: 0.5168 - val_loss: 1.6615 - val_weighted_acc: 0.5163\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.6362 - weighted_acc: 0.5197 - val_loss: 1.6517 - val_weighted_acc: 0.5207\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.6216 - weighted_acc: 0.5248 - val_loss: 1.6435 - val_weighted_acc: 0.5247\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.6078 - weighted_acc: 0.5286 - val_loss: 1.6322 - val_weighted_acc: 0.5260\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.5979 - weighted_acc: 0.5317 - val_loss: 1.6220 - val_weighted_acc: 0.5309\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.5854 - weighted_acc: 0.5353 - val_loss: 1.6112 - val_weighted_acc: 0.5337\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.5767 - weighted_acc: 0.5376 - val_loss: 1.6016 - val_weighted_acc: 0.5372\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.5681 - weighted_acc: 0.5403 - val_loss: 1.6060 - val_weighted_acc: 0.5344\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 298s 37ms/step - loss: 1.5579 - weighted_acc: 0.5439 - val_loss: 1.5889 - val_weighted_acc: 0.5415\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.5482 - weighted_acc: 0.5466 - val_loss: 1.5836 - val_weighted_acc: 0.5426\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.5405 - weighted_acc: 0.5484 - val_loss: 1.5793 - val_weighted_acc: 0.5417\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.5323 - weighted_acc: 0.5515 - val_loss: 1.5673 - val_weighted_acc: 0.5464\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 299s 37ms/step - loss: 1.5237 - weighted_acc: 0.5529 - val_loss: 1.5619 - val_weighted_acc: 0.5475\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 309s 39ms/step - loss: 1.5147 - weighted_acc: 0.5563 - val_loss: 1.5570 - val_weighted_acc: 0.5486\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.5065 - weighted_acc: 0.5587 - val_loss: 1.5502 - val_weighted_acc: 0.5511\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.5002 - weighted_acc: 0.5607 - val_loss: 1.5464 - val_weighted_acc: 0.5536\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 296s 37ms/step - loss: 1.4920 - weighted_acc: 0.5632 - val_loss: 1.5401 - val_weighted_acc: 0.5549\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.4876 - weighted_acc: 0.5647 - val_loss: 1.5353 - val_weighted_acc: 0.5556\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.4788 - weighted_acc: 0.5680 - val_loss: 1.5315 - val_weighted_acc: 0.5569\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4749 - weighted_acc: 0.5673 - val_loss: 1.5255 - val_weighted_acc: 0.5582\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4683 - weighted_acc: 0.5700 - val_loss: 1.5216 - val_weighted_acc: 0.5582\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.4604 - weighted_acc: 0.5719 - val_loss: 1.5179 - val_weighted_acc: 0.5612\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.4524 - weighted_acc: 0.5745 - val_loss: 1.5128 - val_weighted_acc: 0.5629\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4480 - weighted_acc: 0.5760 - val_loss: 1.5080 - val_weighted_acc: 0.5650\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4408 - weighted_acc: 0.5786 - val_loss: 1.5047 - val_weighted_acc: 0.5659\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.4365 - weighted_acc: 0.5794 - val_loss: 1.5052 - val_weighted_acc: 0.5651\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4312 - weighted_acc: 0.5804 - val_loss: 1.5023 - val_weighted_acc: 0.5651\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4267 - weighted_acc: 0.5825 - val_loss: 1.4957 - val_weighted_acc: 0.5687\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4213 - weighted_acc: 0.5836 - val_loss: 1.4912 - val_weighted_acc: 0.5694\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4166 - weighted_acc: 0.5844 - val_loss: 1.4882 - val_weighted_acc: 0.5702\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 299s 37ms/step - loss: 1.4105 - weighted_acc: 0.5875 - val_loss: 1.4859 - val_weighted_acc: 0.5724\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4071 - weighted_acc: 0.5881 - val_loss: 1.4801 - val_weighted_acc: 0.5739\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 295s 37ms/step - loss: 1.4013 - weighted_acc: 0.5896 - val_loss: 1.4809 - val_weighted_acc: 0.5735\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.3999 - weighted_acc: 0.5895 - val_loss: 1.4785 - val_weighted_acc: 0.5743\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.3968 - weighted_acc: 0.5909 - val_loss: 1.4852 - val_weighted_acc: 0.5701\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 294s 37ms/step - loss: 1.3905 - weighted_acc: 0.5930 - val_loss: 1.4722 - val_weighted_acc: 0.5755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22411482438>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.fit(\n",
    "    x=[decoder_input_train, encoder_input_train],\n",
    "    y=decoder_target_train,\n",
    "    sample_weight = sample_weights_train,\n",
    "    epochs=50,\n",
    "    batch_size = 64,\n",
    "    validation_data = ([decoder_input_val, encoder_input_val], decoder_target_val, sample_weights_val),\n",
    "    callbacks = [ModelCheckpoint(\"keras_models/attention_simple_best.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I'll go in a minute.\n",
      "Decoded sentence: Jag ska gå mig mig mig.\n",
      "\n",
      "-\n",
      "Input sentence: I said Tom is a friend.\n",
      "Decoded sentence: Jag sag Tom är en för dig.\n",
      "\n",
      "-\n",
      "Input sentence: I never saw you.\n",
      "Decoded sentence: Jag båg var var dig.\n",
      "\n",
      "-\n",
      "Input sentence: I feel like playing, too.\n",
      "Decoded sentence: Jag känner att att ppat i gå det.\n",
      "\n",
      "-\n",
      "Input sentence: Tom drives.\n",
      "Decoded sentence: Tom brov.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's lucky.\n",
      "Decoded sentence: Tom är kock.\n",
      "\n",
      "-\n",
      "Input sentence: How about a contest?\n",
      "Decoded sentence: Hur skulla kan inten?\n",
      "\n",
      "-\n",
      "Input sentence: I can help you out.\n",
      "Decoded sentence: Jag kan hale dig ut.\n",
      "\n",
      "-\n",
      "Input sentence: I can't remember the lyrics.\n",
      "Decoded sentence: Jag kan inte mig här slar.\n",
      "\n",
      "-\n",
      "Input sentence: Keep dancing.\n",
      "Decoded sentence: Håll da kinn.\n",
      "\n",
      "-\n",
      "Input sentence: I'll bring Tom.\n",
      "Decoded sentence: Jag kommer Tom.\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Var tulligele.\n",
      "\n",
      "-\n",
      "Input sentence: We can both do it.\n",
      "Decoded sentence: Vi kan bå det det det.\n",
      "\n",
      "-\n",
      "Input sentence: Who are Tom's friends?\n",
      "Decoded sentence: Vem är Tom rin inter?\n",
      "\n",
      "-\n",
      "Input sentence: That doesn't surprise me.\n",
      "Decoded sentence: Det det inte sanster är mig.\n",
      "\n",
      "-\n",
      "Input sentence: What do you need to know?\n",
      "Decoded sentence: Vad gå du inte tela nela du?\n",
      "\n",
      "-\n",
      "Input sentence: The earth is smaller than the sun.\n",
      "Decoded sentence: Det har den somllen i han son sunna.\n",
      "\n",
      "-\n",
      "Input sentence: Tom hates liars.\n",
      "Decoded sentence: Tom har sig skar.\n",
      "\n",
      "-\n",
      "Input sentence: Who received it?\n",
      "Decoded sentence: Vem kor det?\n",
      "\n",
      "-\n",
      "Input sentence: He was devastated.\n",
      "Decoded sentence: Han var vararar.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is multilingual.\n",
      "Decoded sentence: Tom är miter slat.\n",
      "\n",
      "-\n",
      "Input sentence: Have a nice day.\n",
      "Decoded sentence: Ha en inte kag.\n",
      "\n",
      "-\n",
      "Input sentence: I'll go ask Tom.\n",
      "Decoded sentence: Jag ska gå att Tom.\n",
      "\n",
      "-\n",
      "Input sentence: I'll meet you back on the ship.\n",
      "Decoded sentence: Jag ska mig till kala han här här.\n",
      "\n",
      "-\n",
      "Input sentence: Tom can't decide what to buy.\n",
      "Decoded sentence: Tom kan inte kande vad det ut.\n",
      "\n",
      "-\n",
      "Input sentence: Tom looked at the floor.\n",
      "Decoded sentence: Tom ser det det för för skor.\n",
      "\n",
      "-\n",
      "Input sentence: I think that's a hoax.\n",
      "Decoded sentence: Jag tror att det är en har.\n",
      "\n",
      "-\n",
      "Input sentence: I was quite hungry\n",
      "Decoded sentence: Jag var trattaragkälöökuuk\n",
      "\n",
      "-\n",
      "Input sentence: I just bought this.\n",
      "Decoded sentence: Jag breste det här här.\n",
      "\n",
      "-\n",
      "Input sentence: Do you miss it?\n",
      "Decoded sentence: Tycker du det här?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(30):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_val[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_sentences_val[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite hilarious results.\n",
    "THe model often gets the start of a sentence right, and then derails at some point. \n",
    "The derailing is of course somewhat expected when the model is fed incorrect data from previous timesteps.\n",
    "\n",
    "The model is still improving with each epoch, but I would like to attempt a more suitable model instead of allowing it more training time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

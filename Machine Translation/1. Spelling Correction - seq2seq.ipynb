{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Inspired by [Maria Movin (2018)](http://www.nada.kth.se/~ann/exjobb/maria_movin.pdf) I want to attempt to perform spelling correction using a machine translation model.\n",
    "She uses a very similar model to what I used in `1. Machine Translation - Character Level Model`.\n",
    "\n",
    "I will attempt to use a similar model, but will also try to use an embedding layer for the characters.\n",
    "Perhaps the model could learn similarities between some characters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "I will be using the [Twitter Typo](http://luululu.com/tweet/) data set to train and evaluate my model.\n",
    "It consists of 39 172 misspelled words and their correct spelling, including some meta data about what type of misspelling it is.\n",
    "This data set was used by [Gosh and Kristensson (2015)](https://arxiv.org/pdf/1709.06429.pdf) to learn about common spelling mistakes in order to generate a larger data set of corrected words.\n",
    "As I am running my model on my weak laptop I will opt to not extend the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/twitter_typos/typo-corpus-r1.txt'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "rows = []\n",
    "for line in lines:\n",
    "    rows.append(line.split('\\t')[:3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['york', 'work', 'R2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = rows[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=rows, columns=['incorrect', 'correct', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>york</td>\n",
       "      <td>work</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prople</td>\n",
       "      <td>people</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hring</td>\n",
       "      <td>hiring</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prople</td>\n",
       "      <td>people</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prople</td>\n",
       "      <td>people</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incorrect correct type\n",
       "0      york    work   R2\n",
       "1    prople  people   R2\n",
       "2     hring  hiring   RM\n",
       "3    prople  people   R2\n",
       "4    prople  people   R2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39172, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a begginging of word and end of word character to all targets, this will be used to seed new words and determine where a word ends. \n",
    "I will use `\\t` as start of word and `\\n` as end of word characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['correct'] = df['correct'].apply(lambda x: '\\t' + x + '\\n' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four kind of types are:\n",
    "1. INSERT (IN): a character is added to the original word.\n",
    "2. REMOVE (RM): a character is removed from the original word.\n",
    "3. REPLACE1 (R1): the order of character is different from the original word (the number of differences is one).\n",
    "4. REPLACE2 (R2): a character is different from the original word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Misspellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1561b16ba58>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAEvCAYAAABPOhisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSYUw9CVJKoShL0lSIf4/XclfXdDnt1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1561b0226a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(8,4.5))\n",
    "sns.countplot(x='type', data=df)\n",
    "ax.set_title('Types of Spelling Errors in the Twitter Typo Data Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct incorrect words: 9294\n",
      "Distinct correct words: 2466\n"
     ]
    }
   ],
   "source": [
    "print(\"Distinct incorrect words: {}\".format(df['incorrect'].nunique()))\n",
    "print(\"Distinct correct words: {}\".format(df['correct'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incorrect    0\n",
       "correct      0\n",
       "type         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Unique Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_char(word):\n",
    "    for c in word:\n",
    "        chars.add(c)\n",
    "chars = set()\n",
    "df['incorrect'].apply(add_char);\n",
    "df['correct'].apply(add_char);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39172.000000\n",
       "mean         4.124553\n",
       "std          2.088488\n",
       "min          1.000000\n",
       "25%          3.000000\n",
       "50%          3.000000\n",
       "75%          5.000000\n",
       "max         16.000000\n",
       "Name: incorrect, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['incorrect'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39172.000000\n",
       "mean         6.058128\n",
       "std          2.173799\n",
       "min          2.000000\n",
       "25%          4.000000\n",
       "50%          6.000000\n",
       "75%          7.000000\n",
       "max         17.000000\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['correct'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_input_len = df['incorrect'].apply(len).max()\n",
    "max_output_len = df['correct'].apply(len).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Characters as Integers\n",
    "I will encode all characters as integers to make them compatible with the Keras Embedding layer. I keep `0` for padding.\n",
    "All words will be coverted into lists of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_mapping = dict(zip(sorted(list(chars)), np.arange(1, vocab_size+1)))\n",
    "reversed_char_mapping = dict([(b, a) for a, b in char_mapping.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reversed_char_mapping[0] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['X'] = df['incorrect'].apply(lambda x: [char_mapping[c] for c in x])\n",
    "df['y'] = df['correct'].apply(lambda x: [char_mapping[c] for c in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data into training, dev and test set\n",
    "When splitting the data into different sets I will be using `type` to strattify the data.\n",
    "I think it is a good idea to make sure that all sets are representable of all types of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, stratify=df['type'], test_size=1/10, random_state=1)\n",
    "df_train, df_dev = train_test_split(df_train, stratify=df_train['type'], test_size=(2/9), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1bd332d2630>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHgAAAFBCAYAAAAMvxiBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd336946d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 3, figsize=(16,4.5))\n",
    "for i, name, dfi in zip(np.arange(3), [\"Train\", \"Dev\", \"Test\"], [df_train, df_dev, df_test]):\n",
    "    sns.countplot(data=dfi, x='type', ax=ax[i], order=['IN', 'RM', 'R1', 'R2'])\n",
    "    ax[i].set_title(name)\n",
    "f.tight_layout(rect = [0, 0, 1, .97])\n",
    "f.suptitle(\"Distribution of Spelling Errors in Train, Dev and Test Sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = df_train['X'].values, df_train['y'].values\n",
    "X_dev, y_dev = df_dev['X'].values, df_dev['y'].values\n",
    "X_test, y_test = df_test['X'].values, df_test['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad Data\n",
    "To allow a Keras RNN to process data in batches the whole batces all sequences in one batch needs to be the same length.\n",
    "This is acheived by padding sentences with trailing `0`'s that will be ignored during training. \n",
    "\n",
    "To avoid padding all sentences to be as long as the longest sentence in each set I will sort the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_idx_train = np.argsort(list(map(lambda x: len(x), X_train)))\n",
    "sorted_idx_dev = np.argsort(list(map(lambda x: len(x), X_dev)))\n",
    "sorted_idx_test = np.argsort(list(map(lambda x: len(x), X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train[sorted_idx_train]\n",
    "y_train = y_train[sorted_idx_train]\n",
    "df_train = df_train.iloc[sorted_idx_train]\n",
    "\n",
    "X_dev = X_dev[sorted_idx_dev]\n",
    "y_dev = y_dev[sorted_idx_dev]\n",
    "df_dev = df_dev.iloc[sorted_idx_dev]\n",
    "\n",
    "X_test = X_test[sorted_idx_test]\n",
    "y_test = y_test[sorted_idx_test]\n",
    "df_test = df_test.iloc[sorted_idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator for the padded sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(i, n):\n",
    "    arr = np.zeros(n)\n",
    "    arr[i] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "class ShortPaddingGeneratorSeq2Seq(Sequence):\n",
    "    \"\"\"\n",
    "    Class for generating padded sequences\n",
    "    \"\"\"\n",
    "    def __init__(self, x_set, y_set, batch_size, return_sample_weights=True, one_hot_encode=False):\n",
    "        self.return_sample_weights = return_sample_weights\n",
    "        self.batch_size = batch_size\n",
    "        self.x, self.y, self.sample_weights = [], [], []\n",
    "        self.x2 = []\n",
    "        # Pad Data so all batches have sequences of equal length\n",
    "        for idx in range(int(np.ceil(len(x_set) / float(self.batch_size)))):\n",
    "            batch_x = x_set[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            batch_y = y_set[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            \n",
    "            # The input is sorted so the last sequence is the longest\n",
    "            max_len_x = len(batch_x[-1])\n",
    "            max_len_y = len(batch_y[-1])\n",
    "            batch_x = np.array(pad_sequences(batch_x, maxlen=max_len_x, padding='post'))\n",
    "            batch_y = np.array(pad_sequences(batch_y, maxlen=max_len_y, padding='post'))\n",
    "            \n",
    "            #self.sample_weights.append(batch_x != 0)\n",
    "            self.sample_weights.append(batch_y[:,1:] != 0)\n",
    "            \n",
    "            if one_hot_encode:\n",
    "                batch_x = np.array([np.array([one_hot(i, vocab_size+1) for i in sentence]) for sentence in batch_x])\n",
    "                batch_y = np.array([np.array([one_hot(i, vocab_size+1) for i in sentence]) for sentence in batch_y])\n",
    "            \n",
    "            self.x.append(batch_x)\n",
    "            self.y.append(batch_y[:,1:])\n",
    "            # The decoder input s\n",
    "            self.x2.append(batch_y[:,:-1])\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch the batches\n",
    "        if self.return_sample_weights:\n",
    "            return [self.x[idx], self.x2[idx]], self.y[idx], self.sample_weights[idx]\n",
    "        else:\n",
    "            return [self.x[idx], self.x2[idx]], self.y[idx]\n",
    "    \n",
    "    def set_return_sample_weights(self, flag):\n",
    "        self.return_sample_weights = flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the generators for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = ShortPaddingGeneratorSeq2Seq(X_train, y_train, batch_size=64, one_hot_encode=True)\n",
    "dev_gen = ShortPaddingGeneratorSeq2Seq(X_dev, y_dev, batch_size=64, one_hot_encode=True)\n",
    "test_gen = ShortPaddingGeneratorSeq2Seq(X_test, y_test, batch_size=64, one_hot_encode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 2, 30)\n",
      "(64, 3, 30)\n",
      "(64, 3, 30)\n"
     ]
    }
   ],
   "source": [
    "print(train_gen[100][0][0].shape)\n",
    "print(train_gen[100][0][1].shape)\n",
    "print(train_gen[100][1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoded Characters\n",
    "First let's use the model proposed in Francois Chollet's article [A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "batch_size = 64\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define the encoder to have one hidden LSTM layer and output its state\n",
    "encoder_inputs = Input(shape=(None, vocab_size+1))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Only save the states of the encoder, we don't care about it's output\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder, it will use the state of the encoder as its initial state\n",
    "decoder_inputs = Input(shape=(None, vocab_size+1))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size+1, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', weighted_metrics=['accuracy'], sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "429/429 [==============================] - 45s 105ms/step - loss: 0.3171 - weighted_acc: 0.9044 - val_loss: 0.3307 - val_weighted_acc: 0.9021\n",
      "Epoch 2/10\n",
      "429/429 [==============================] - 50s 117ms/step - loss: 0.2635 - weighted_acc: 0.9201 - val_loss: 0.3003 - val_weighted_acc: 0.9102\n",
      "Epoch 3/10\n",
      "429/429 [==============================] - 50s 116ms/step - loss: 0.2311 - weighted_acc: 0.9286 - val_loss: 0.2964 - val_weighted_acc: 0.9081\n",
      "Epoch 4/10\n",
      "429/429 [==============================] - 52s 120ms/step - loss: 0.2088 - weighted_acc: 0.9351 - val_loss: 0.2982 - val_weighted_acc: 0.9105\n",
      "Epoch 5/10\n",
      "429/429 [==============================] - 52s 121ms/step - loss: 0.1963 - weighted_acc: 0.9380 - val_loss: 0.2754 - val_weighted_acc: 0.9185\n",
      "Epoch 6/10\n",
      "429/429 [==============================] - 54s 126ms/step - loss: 0.1776 - weighted_acc: 0.9435 - val_loss: 0.2750 - val_weighted_acc: 0.9192\n",
      "Epoch 7/10\n",
      "429/429 [==============================] - 56s 131ms/step - loss: 0.1681 - weighted_acc: 0.9449 - val_loss: 0.2730 - val_weighted_acc: 0.9180\n",
      "Epoch 8/10\n",
      "429/429 [==============================] - 59s 138ms/step - loss: 0.1584 - weighted_acc: 0.9481 - val_loss: 0.2747 - val_weighted_acc: 0.9176\n",
      "Epoch 9/10\n",
      "429/429 [==============================] - 62s 145ms/step - loss: 0.1503 - weighted_acc: 0.9499 - val_loss: 0.2799 - val_weighted_acc: 0.9167\n",
      "Epoch 10/10\n",
      "429/429 [==============================] - 61s 142ms/step - loss: 0.1438 - weighted_acc: 0.9515 - val_loss: 0.2739 - val_weighted_acc: 0.9201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f431abe1d0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "          epochs=10,\n",
    "          validation_data=dev_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model with Chollet's inference model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_decoder_seq_length = 20\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, vocab_size + 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, char_mapping['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        #print(output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reversed_char_mapping[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, vocab_size + 1))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input word: yu\n",
      "Target word: you\n",
      "Corrected word: you\n",
      "\n",
      "-\n",
      "Input word: meg\n",
      "Target word: me\n",
      "Corrected word: me\n",
      "\n",
      "-\n",
      "Input word: im\n",
      "Target word: i\n",
      "Corrected word: i\n",
      "\n",
      "-\n",
      "Input word: forr\n",
      "Target word: for\n",
      "Corrected word: or\n",
      "\n",
      "-\n",
      "Input word: hav\n",
      "Target word: has\n",
      "Corrected word: a\n",
      "\n",
      "-\n",
      "Input word: tha\n",
      "Target word: the\n",
      "Corrected word: a\n",
      "\n",
      "-\n",
      "Input word: tqake\n",
      "Target word: take\n",
      "Corrected word: a\n",
      "\n",
      "-\n",
      "Input word: gottan\n",
      "Target word: gotta\n",
      "Corrected word: on\n",
      "\n",
      "-\n",
      "Input word: nw\n",
      "Target word: now\n",
      "Corrected word: on\n",
      "\n",
      "-\n",
      "Input word: goona\n",
      "Target word: gonna\n",
      "Corrected word: on\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "for seq_index in np.random.randint(0, len(X_train), 10):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = X_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(np.array([np.array([one_hot(i, vocab_size+1) for i in input_seq])]))\n",
    "    print('-')\n",
    "    print('Input word:', df_train.iloc[seq_index]['incorrect'])\n",
    "    print('Target word:', df_train.iloc[seq_index]['correct'].strip())\n",
    "    print('Corrected word:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has learned some patterns, but seems to often resort to outputting short and simple words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler Model - Single RNN\n",
    "I want to try setting up a model that just uses a single RNN, instead of the decoder encoder model.\n",
    "As I really like Embeddings, I will include an imbedding layer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad the Data\n",
    "It seems like it's not straight forward to implement a RNN with input sequences of length `N` and output sequences of length `M` when `N!=M`.\n",
    "Instead I will limit my model by setting a fixed input and output length and pad all sequences to be this length.\n",
    "\n",
    "My model will not be able to handle targets longer than this limit, and will always produce outputs of exactly that length which I will have to terminate at the stop character `\\n`.\n",
    "\n",
    "Also, since I won't know the length of target words in a real use case, I don't want to process my data in batches of similar size. \n",
    "All inputs should generate output sequences of the exact same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "max_len = max(max_input_len, max_output_len)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's remove the start of word token from the outputs as it is not necessary in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_stripped = [seq[1:] for seq in y_train]\n",
    "y_dev_stripped = [seq[1:] for seq in y_dev]\n",
    "y_test_stripped = [seq[1:] for seq in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = np.array(pad_sequences(X_train, maxlen=max_len, padding='post'))\n",
    "y_train_padded = np.array(pad_sequences(y_train_stripped, maxlen=max_len, padding='post'))\n",
    "X_dev_padded = np.array(pad_sequences(X_dev, maxlen=max_len, padding='post'))\n",
    "y_dev_padded = np.array(pad_sequences(y_dev_stripped, maxlen=max_len, padding='post'))\n",
    "X_test_padded = np.array(pad_sequences(X_test, maxlen=max_len, padding='post'))\n",
    "y_test_padded = np.array(pad_sequences(y_test_stripped, maxlen=max_len, padding='post'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time I am not doing one hot encoding of the input, instead I will use an Embeddings layer. I will still one hot encode the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_padded = np.array([np.array([one_hot(i, vocab_size+1) for i in sentence]) for sentence in y_train_padded])\n",
    "y_dev_padded = np.array([np.array([one_hot(i, vocab_size+1) for i in sentence]) for sentence in y_dev_padded])\n",
    "y_test_padded = np.array([np.array([one_hot(i, vocab_size+1) for i in sentence]) for sentence in y_test_padded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, Dropout\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vocab size is 29. I have no idea what number embedding dimensions is suitable, so let's just embed these 29 characters into 10 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_input = Input(shape=(None,))\n",
    "embedding = Embedding(vocab_size+1, embedding_dim, mask_zero = True)(model_input)\n",
    "x = Dropout(rate=.25)(embedding)\n",
    "x = LSTM(latent_dim, return_sequences=True)(x)\n",
    "model_output = Dense(vocab_size + 1, activation='softmax')(x)\n",
    "simple_rnn1 = Model(model_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_rnn1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27419 samples, validate on 7835 samples\n",
      "Epoch 1/2\n",
      "27419/27419 [==============================] - 120s 4ms/step - loss: 2.1676 - acc: 0.3967 - val_loss: 1.5059 - val_acc: 0.5982\n",
      "Epoch 2/2\n",
      "27419/27419 [==============================] - 135s 5ms/step - loss: 1.4863 - acc: 0.5987 - val_loss: 1.2422 - val_acc: 0.6626\n"
     ]
    }
   ],
   "source": [
    "callback = simple_rnn1.fit(X_train_padded, y_train_padded,\n",
    "          epochs=2,\n",
    "          validation_data=[X_dev_padded, y_dev_padded],\n",
    "          callbacks = [History()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time significantly increased now that all sequences are of equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_int_sequence(sequence):\n",
    "    word = \"\"\n",
    "    for token_index in sequence:\n",
    "        c = reversed_char_mapping[token_index]\n",
    "        if c not in ('\\n', '<pad>'):\n",
    "            word += c\n",
    "        else:\n",
    "            break\n",
    "    return word\n",
    "\n",
    "def evaluate_model(model, X, y, pred_idx):\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X[pred_idx])\n",
    "    \n",
    "    # Print evaluation\n",
    "    for idx, pred in zip(pred_idx, predictions):\n",
    "        print(\"Input: \", decode_int_sequence(X[idx]))\n",
    "        print(\"Target: \",decode_int_sequence(y[idx].argmax(1)))\n",
    "        print(\"Output: \", decode_int_sequence(pred.argmax(1)))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  yu\n",
      "Target:  you\n",
      "Output:  yoooooooooooooooo\n",
      "\n",
      "Input:  meg\n",
      "Target:  me\n",
      "Output:  meggggggggggggggg\n",
      "\n",
      "Input:  im\n",
      "Target:  i\n",
      "Output:  issssssssssssssss\n",
      "\n",
      "Input:  forr\n",
      "Target:  for\n",
      "Output:  for\n",
      "\n",
      "Input:  hav\n",
      "Target:  has\n",
      "Output:  havvvvvvvvvvvvvvv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "evaluate_model(simple_rnn1, X_train_padded, y_train_padded, np.random.randint(0, len(X_train), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, the model has already learned some stuff and actually got `forr` -> `for` right!\n",
    "Let's allow it some more training, this time with shuffled batches and a set batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27419 samples, validate on 7835 samples\n",
      "Epoch 1/10\n",
      "27419/27419 [==============================] - 84s 3ms/step - loss: 1.2488 - acc: 0.6681 - val_loss: 1.1364 - val_acc: 0.6906\n",
      "Epoch 2/10\n",
      "27419/27419 [==============================] - 96s 3ms/step - loss: 1.2076 - acc: 0.6782 - val_loss: 1.1132 - val_acc: 0.6977\n",
      "Epoch 3/10\n",
      "27419/27419 [==============================] - 94s 3ms/step - loss: 1.1760 - acc: 0.6862 - val_loss: 1.0889 - val_acc: 0.7013\n",
      "Epoch 4/10\n",
      "27419/27419 [==============================] - 94s 3ms/step - loss: 1.1462 - acc: 0.6933 - val_loss: 1.0742 - val_acc: 0.7078\n",
      "Epoch 5/10\n",
      "27419/27419 [==============================] - 96s 4ms/step - loss: 1.1163 - acc: 0.7023 - val_loss: 1.0550 - val_acc: 0.7107\n",
      "Epoch 6/10\n",
      "27419/27419 [==============================] - 95s 3ms/step - loss: 1.0882 - acc: 0.7091 - val_loss: 1.0382 - val_acc: 0.7153\n",
      "Epoch 7/10\n",
      "27419/27419 [==============================] - 94s 3ms/step - loss: 1.0645 - acc: 0.7166 - val_loss: 1.0214 - val_acc: 0.7193\n",
      "Epoch 8/10\n",
      "27419/27419 [==============================] - 93s 3ms/step - loss: 1.0391 - acc: 0.7217 - val_loss: 1.0140 - val_acc: 0.7213\n",
      "Epoch 9/10\n",
      "27419/27419 [==============================] - 93s 3ms/step - loss: 1.0186 - acc: 0.7274 - val_loss: 1.0021 - val_acc: 0.7240\n",
      "Epoch 10/10\n",
      "27419/27419 [==============================] - 92s 3ms/step - loss: 0.9997 - acc: 0.7301 - val_loss: 0.9932 - val_acc: 0.7289\n"
     ]
    }
   ],
   "source": [
    "callback = simple_rnn1.fit(X_train_padded, y_train_padded,\n",
    "          epochs=10,\n",
    "          batch_size = 128,\n",
    "          shuffle = True,\n",
    "          validation_data=[X_dev_padded, y_dev_padded],\n",
    "          callbacks = [History()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  yu\n",
      "Target:  you\n",
      "Output:  yoooooooooooooooo\n",
      "\n",
      "Input:  meg\n",
      "Target:  me\n",
      "Output:  me\n",
      "\n",
      "Input:  im\n",
      "Target:  i\n",
      "Output:  issssssssssssssss\n",
      "\n",
      "Input:  forr\n",
      "Target:  for\n",
      "Output:  for\n",
      "\n",
      "Input:  hav\n",
      "Target:  has\n",
      "Output:  havvvvvvvvvvvvvvv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "evaluate_model(simple_rnn1, X_train_padded, y_train_padded, np.random.randint(0, len(X_train), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_rnn1.save('keras_models/spell_correction_simple_rnn1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model get's one more word right this time! `meg` -> `me`!\n",
    "\n",
    "It produces many funny looking output like `havvvvvvvvvvvvvvv`. \n",
    "I think this might be due to me using `mask_zero` in the Embedding layer, and no sample weights. \n",
    "This means I am ignoring the characters being output when the input character is padding. \n",
    "I should try to use sample weights instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Simpel model number two\n",
    "Let's use sample weights instead of mask_zero in the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_input = Input(shape=(None,))\n",
    "embedding = Embedding(vocab_size+1, embedding_dim, mask_zero = False)(model_input)\n",
    "x = Dropout(rate=.25)(embedding)\n",
    "x = LSTM(latent_dim, return_sequences=True)(x)\n",
    "model_output = Dense(vocab_size + 1, activation='softmax')(x)\n",
    "simple_rnn2 = Model(model_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_rnn2.compile(optimizer='adam', loss='categorical_crossentropy', sample_weight_mode='temporal', weighted_metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sample_wights = y_train_padded[:,:,1:].any(2)\n",
    "y_dev_sample_wights = y_dev_padded[:,:,1:].any(2)\n",
    "y_test_sample_wights = y_test_padded[:,:,1:].any(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27419 samples, validate on 7835 samples\n",
      "Epoch 1/2\n",
      "27419/27419 [==============================] - 132s 5ms/step - loss: 2.0710 - weighted_acc: 0.4243 - val_loss: 1.3744 - val_weighted_acc: 0.6290\n",
      "Epoch 2/2\n",
      "27419/27419 [==============================] - 127s 5ms/step - loss: 1.3535 - weighted_acc: 0.6301 - val_loss: 1.0565 - val_weighted_acc: 0.7118\n"
     ]
    }
   ],
   "source": [
    "callback = simple_rnn2.fit(X_train_padded, y_train_padded, \n",
    "          sample_weight=y_train_sample_wights,\n",
    "          epochs=2,\n",
    "          validation_data=[X_dev_padded, y_dev_padded, y_dev_sample_wights], \n",
    "          callbacks = [History()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  yu\n",
      "Target:  you\n",
      "Output:  you\n",
      "\n",
      "Input:  meg\n",
      "Target:  me\n",
      "Output:  meg\n",
      "\n",
      "Input:  im\n",
      "Target:  i\n",
      "Output:  is\n",
      "\n",
      "Input:  forr\n",
      "Target:  for\n",
      "Output:  fore\n",
      "\n",
      "Input:  hav\n",
      "Target:  has\n",
      "Output:  hav\n",
      "\n",
      "Input:  tha\n",
      "Target:  the\n",
      "Output:  the\n",
      "\n",
      "Input:  tqake\n",
      "Target:  take\n",
      "Output:  thekk\n",
      "\n",
      "Input:  gottan\n",
      "Target:  gotta\n",
      "Output:  got\n",
      "\n",
      "Input:  nw\n",
      "Target:  now\n",
      "Output:  now\n",
      "\n",
      "Input:  goona\n",
      "Target:  gonna\n",
      "Output:  goonle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "evaluate_model(simple_rnn2, X_train_padded, y_train_padded, np.random.randint(0, len(X_train), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, using sample weights based on the targets instead of the inputs really shows results. \n",
    "The model has learned a lot of the words in the training set after just two epochs.\n",
    "Let's give it some more training time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27419 samples, validate on 7835 samples\n",
      "Epoch 1/10\n",
      "27419/27419 [==============================] - 83s 3ms/step - loss: 1.1861 - weighted_acc: 0.6775 - val_loss: 1.0024 - val_weighted_acc: 0.7266\n",
      "Epoch 2/10\n",
      "27419/27419 [==============================] - 84s 3ms/step - loss: 1.1421 - weighted_acc: 0.6891 - val_loss: 0.9705 - val_weighted_acc: 0.7350\n",
      "Epoch 3/10\n",
      "27419/27419 [==============================] - 82s 3ms/step - loss: 1.0993 - weighted_acc: 0.7009 - val_loss: 0.9401 - val_weighted_acc: 0.7425\n",
      "Epoch 4/10\n",
      "27419/27419 [==============================] - 81s 3ms/step - loss: 1.0595 - weighted_acc: 0.7129 - val_loss: 0.9123 - val_weighted_acc: 0.7515\n",
      "Epoch 5/10\n",
      "27419/27419 [==============================] - 82s 3ms/step - loss: 1.0298 - weighted_acc: 0.7209 - val_loss: 0.8917 - val_weighted_acc: 0.7550\n",
      "Epoch 6/10\n",
      "27419/27419 [==============================] - 81s 3ms/step - loss: 0.9958 - weighted_acc: 0.7297 - val_loss: 0.8705 - val_weighted_acc: 0.7608\n",
      "Epoch 7/10\n",
      "27419/27419 [==============================] - 80s 3ms/step - loss: 0.9681 - weighted_acc: 0.7369 - val_loss: 0.8523 - val_weighted_acc: 0.7658\n",
      "Epoch 8/10\n",
      "27419/27419 [==============================] - 80s 3ms/step - loss: 0.9410 - weighted_acc: 0.7451 - val_loss: 0.8361 - val_weighted_acc: 0.7689\n",
      "Epoch 9/10\n",
      "27419/27419 [==============================] - 80s 3ms/step - loss: 0.9223 - weighted_acc: 0.7488 - val_loss: 0.8266 - val_weighted_acc: 0.7703\n",
      "Epoch 10/10\n",
      "27419/27419 [==============================] - 82s 3ms/step - loss: 0.9010 - weighted_acc: 0.7550 - val_loss: 0.8159 - val_weighted_acc: 0.7759\n"
     ]
    }
   ],
   "source": [
    "callback = simple_rnn2.fit(X_train_padded, y_train_padded, \n",
    "          sample_weight=y_train_sample_wights,\n",
    "          epochs=10,\n",
    "          batch_size = 128,\n",
    "          shuffle = True,\n",
    "          validation_data=[X_dev_padded, y_dev_padded, y_dev_sample_wights], \n",
    "          callbacks = [History()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  yu\n",
      "Target:  you\n",
      "Output:  you\n",
      "\n",
      "Input:  meg\n",
      "Target:  me\n",
      "Output:  me\n",
      "\n",
      "Input:  im\n",
      "Target:  i\n",
      "Output:  is\n",
      "\n",
      "Input:  forr\n",
      "Target:  for\n",
      "Output:  for\n",
      "\n",
      "Input:  hav\n",
      "Target:  has\n",
      "Output:  has\n",
      "\n",
      "Input:  tha\n",
      "Target:  the\n",
      "Output:  the\n",
      "\n",
      "Input:  tqake\n",
      "Target:  take\n",
      "Output:  thek\n",
      "\n",
      "Input:  gottan\n",
      "Target:  gotta\n",
      "Output:  got\n",
      "\n",
      "Input:  nw\n",
      "Target:  now\n",
      "Output:  now\n",
      "\n",
      "Input:  goona\n",
      "Target:  gonna\n",
      "Output:  googa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "evaluate_model(simple_rnn2, X_train_padded, y_train_padded, np.random.randint(0, len(X_train), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  wifi\n",
      "Target:  wii\n",
      "Output:  wii\n",
      "\n",
      "Input:  em\n",
      "Target:  me\n",
      "Output:  ee\n",
      "\n",
      "Input:  toon\n",
      "Target:  too\n",
      "Output:  too\n",
      "\n",
      "Input:  bing\n",
      "Target:  being\n",
      "Output:  bin\n",
      "\n",
      "Input:  av\n",
      "Target:  a\n",
      "Output:  av\n",
      "\n",
      "Input:  imo\n",
      "Target:  im\n",
      "Output:  is\n",
      "\n",
      "Input:  appreciatet\n",
      "Target:  appreciated\n",
      "Output:  appreciatee\n",
      "\n",
      "Input:  tha\n",
      "Target:  the\n",
      "Output:  the\n",
      "\n",
      "Input:  fucc\n",
      "Target:  fuck\n",
      "Output:  fuck\n",
      "\n",
      "Input:  nd\n",
      "Target:  and\n",
      "Output:  nnd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "evaluate_model(simple_rnn2, X_dev_padded, y_dev_padded, np.random.randint(0, len(X_dev), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, far from perfect but still gets a lot of words right! \n",
    "Some targets are not obvious for a human either, especially without context.\n",
    "\n",
    "More training time could probably help to improve the model, but first let's have a quick look at the embeddings we have created. Let's visualize with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn2.save('keras_models/spell_correction_simple_rnn2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the character embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = simple_rnn2.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "\n",
    "embedding_matrix_2_dim = pca.fit_transform(embedding_matrix)\n",
    "embedding_matrix_2_dim = MinMaxScaler().fit_transform(X=embedding_matrix_2_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25834391,  0.17576526], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43410915"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of information is lost when going from 10 dimensions to 2, but we still have 43% of the explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x15634cc0d68>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAHtCAYAAADiEfyeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15634828470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_xlim([-.01, 1.01])\n",
    "ax.set_ylim([-.01, 1.01])\n",
    "for char, i in char_mapping.items():\n",
    "    x, y = embedding_matrix_2_dim[i]\n",
    "    ax.text(x, y, char)\n",
    "\n",
    "ax.set_title('Character Embeddings of Simple Model 2, Two Principal Components')\n",
    "ax.set_xlabel('First Principal Component')\n",
    "ax.set_ylabel('Second Principal Component')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't really see any obvious patterns, except possibly that k and c are very close. \n",
    "I had hopes that characters that are close by on the keyboard would appear close in the embedding, as these characters are supposedly often interchanged in spelling errors. \n",
    "This is true for a few characters, but far from all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

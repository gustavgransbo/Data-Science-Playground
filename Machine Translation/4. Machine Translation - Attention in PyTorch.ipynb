{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook I will once again tackle the task of machine translation using an encoder-decoder setup. I will also give attention a more honest try compared to last time.\n",
    "\n",
    "I have just started trying out PyTorch instead of Keras, and have thus far enjoyed the increased flexibility. It turns out that PyTorch offers a [tutorial for machine translation using an encoder-decoder setup and attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-download-intermediate-seq2seq-translation-tutorial-py), which I will draw a lot of inspiration from.\n",
    "\n",
    "Some notes on the baseline model I will use:\n",
    "* Encoder-Decoder Architecture\n",
    "* Operates on word level\n",
    "* Trains embeddings for both languages\n",
    "* Attention used in the decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "I will be using data from the same source as Chollet (exactly as in my previous notebooks), http://www.manythings.org/anki/. I'm using the 17303 sentence long swe-eng data set, that contains english sentences and their swedish translations. The french data set used by Chollet is much larger, but he limited his training set to 10 000 sentences and used 20% of it for validation during training.\n",
    "\n",
    "The data will be implicitly padded in the model so, I don't have to di it explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/swe-eng/swe.txt'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_sentences, target_sentences = [], []\n",
    "for line in lines:\n",
    "    try:\n",
    "        input_text, target_text, *_ = line.split('\\t')\n",
    "    except ValueError:\n",
    "        print(line)\n",
    "        \n",
    "    input_sentences.append(input_text)\n",
    "    target_sentences.append(target_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Normalise\n",
    "I want to word tokenize by using NLTK, and then convert to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_tokenized = [list(map(str.lower, word_tokenize(sentence))) for sentence in input_sentences]\n",
    "target_tokenized = [list(map(str.lower, word_tokenize(sentence, language='swedish'))) for sentence in target_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokenized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate sentence lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention model proposed in the PyTorch tutorial is limited to fixed length sequences, so I will choose a fitting max length. Probably the same as what is used in the PyTorch tutorial: 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_seq_lens = np.array([len(sentence) for sentence in input_tokenized])\n",
    "target_seq_lens = np.array([len(sentence) for sentence in target_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_idx = np.where(input_seq_lens <= max_seq_len)\n",
    "target_idx = np.where(target_seq_lens <= max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16362 input sentences with 10 or fewer characters\n",
      "16502 target sentences with 10 or fewer characters\n"
     ]
    }
   ],
   "source": [
    "print(\"{} input sentences with {} or fewer characters\".format(len(input_idx[0]), max_seq_len))\n",
    "print(\"{} target sentences with {} or fewer characters\".format(len(target_idx[0]), max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_idx = np.intersect1d(input_idx, target_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16186 input sentence pairs with 10 or fewer characters in both languages\n"
     ]
    }
   ],
   "source": [
    "print(\"{} input sentence pairs with {} or fewer characters in both languages\".format(len(keep_idx), max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sentences = np.array(input_tokenized)[keep_idx]\n",
    "target_sentences = np.array(target_tokenized)[keep_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabularies\n",
    "I'll pretty much copy the approach of the PyTorch tutorial to construct my vocabularies. Just doing some small code tweaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"<SOS>\" : 0, \"<EOS>\" : 1}\n",
    "        self.word2count = {}\n",
    "        # Reverse word2index\n",
    "        self.index2word = dict([(b, a) for a, b in self.word2index.items()])\n",
    "        self.n_words = len(self.word2index)\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.add_word(word)\n",
    "        \n",
    "    def add_word(self, word):\n",
    "        # If there any many more tokens than unique tokens, \n",
    "        # it is more efficient to assume the token is already in the vocabulary\n",
    "        try:\n",
    "            self.word2count[word] += 1\n",
    "        except KeyError:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_vocab = Vocab('eng')\n",
    "target_vocab = Vocab('swe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for input_sentence, target_sentence in zip(input_sentences, target_sentences):\n",
    "    input_vocab.add_sentence(input_sentence)\n",
    "    target_vocab.add_sentence(target_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab eng: 4552 unique tokens and 97545 tokens total\n",
      "Vocab swe: 6511 unique tokens and 94538 tokens total\n"
     ]
    }
   ],
   "source": [
    "for vocab in [input_vocab, target_vocab]:\n",
    "    print(\"Vocab %s: %d unique tokens and %d tokens total\" % (vocab.name, vocab.n_words, sum(vocab.word2count.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data into a training and a validation set\n",
    "I will use 8 000 sentances as training set and 2000 as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainig_size, validation_size = 8000, 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_idx = np.random.permutation(len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx, val_idx = shuffle_idx[:trainig_size], shuffle_idx[trainig_size:trainig_size+validation_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_train, input_val = input_sentences[train_idx], input_sentences[val_idx]\n",
    "target_train, target_val = target_sentences[train_idx], target_sentences[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to tensors\n",
    "Just like in the PyTorch tutorial I will set up functions to convert the sentences to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence2indexes(vocab, sentence):\n",
    "    return [vocab.word2index[word] for word in sentence]\n",
    "\n",
    "\n",
    "def sentence2tensor(vocab, sentence):\n",
    "    indexes = sentence2indexes(vocab, sentence)\n",
    "    indexes.append(vocab.word2index['<EOS>'])\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "\n",
    "def pair2tensor(pair):\n",
    "    input_tensor = sentence2tensor(input_vocab, pair[0])\n",
    "    target_tensor = sentence2tensor(target_vocab, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Finally, let's define our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input_word, hidden_state):\n",
    "        embedded = self.embedding(input_word).view(1, 1, -1)\n",
    "        output, hidden_state = self.gru(embedded, hidden_state)\n",
    "        return output, hidden_state\n",
    "    \n",
    "    # Returns a tensor with only zeroes to be used as initial hidden state\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNNAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, dropout_p, max_length):\n",
    "        super(DecoderRNNAttention, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attention = nn.Linear(hidden_size * 2, max_length)\n",
    "        self.attention_combine = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, input_word, hidden_state, encoder_outputs):\n",
    "        \n",
    "        embedded = self.embedding(input_word).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attention_weights = F.softmax(\n",
    "            self.attention(torch.cat((embedded[0], hidden_state[0]), dim = 1)),\n",
    "            dim = 1\n",
    "        )\n",
    "        \n",
    "        attention_applied = torch.bmm(attention_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attention_applied[0]), dim=1)\n",
    "        output = self.attention_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden_state = self.gru(output, hidden_state)\n",
    "        \n",
    "        output = F.log_softmax(self.output(output[0]), dim=1)\n",
    "        return output, hidden_state, attention_weights\n",
    "    \n",
    "    # Returns a tensor with only zeroes to be used as initial hidden state\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The way I set up the model it can only train on one sentance at a time. This will probably add significant overhead, but tackeling that is a task for another day.\n",
    "\n",
    "As in all my previous notebooks I will use teacher forcing to train. However, this time I am able to introduce a new variant! As suggested in the PyTorch tutorial it's possible to alternate between teacher forcing and feeding the previous output as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(encoder, decoder, input_tensor, target_tensor, encoder_optimizer, \n",
    "                decoder_optimizer, criterion, max_length, teacher_forcing_ratio = 1.0):\n",
    "    \n",
    "    encoder_hidden_state = encoder.init_hidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.shape[0]\n",
    "    target_length = target_tensor.shape[0]\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # Encode input tensor\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden_state)\n",
    "        encoder_outputs[ei] = encoder_output\n",
    "        \n",
    "    # Decode input tensor, seeding the decoding with the <BOS> token\n",
    "    decoder_input = torch.tensor([[target_vocab.word2index['<SOS>']]])\n",
    "    decoder_hidden_state = encoder_hidden_state\n",
    "    \n",
    "    # Use teacher-forcing according to dice roll\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            # Forward step and loss\n",
    "            decoder_output, decoer_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden_state, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            # Update input for next step (teacher-forcing)\n",
    "            decoder_input = target_tensor[di]\n",
    "    else:      \n",
    "        for di in range(target_length):\n",
    "            # Forward step and loss\n",
    "            decoder_output, decoer_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden_state, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            # Update input for next step (using output at this step)\n",
    "            log_likelihood, top_word = decoder_output.topk(1) \n",
    "            decoder_input = top_word.squeeze().detach()\n",
    "            \n",
    "            if decoder_input.item() == target_vocab.word2index['<EOS>']:\n",
    "                break\n",
    "    \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensor2sentence(tensor, vocab):\n",
    "    sent = []\n",
    "    for i in tensor:\n",
    "        sent.append(vocab.index2word[i.item()])\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(encoder, decoder, input_tensor, target_tensor, max_length):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        encoder_hidden_state = encoder.init_hidden()\n",
    "\n",
    "        input_length = input_tensor.shape[0]\n",
    "        target_length = target_tensor.shape[0]\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "        # Encode input tensor\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden_state)\n",
    "            encoder_outputs[ei] = encoder_output\n",
    "\n",
    "        # Decode input tensor, seeding the decoding with the <BOS> token\n",
    "        decoder_input = torch.tensor([[target_vocab.word2index['<SOS>']]])\n",
    "        decoder_hidden_state = encoder_hidden_state\n",
    "        decoder_word_outputs = []\n",
    "\n",
    "        for di in range(target_length):\n",
    "            # Forward step and loss\n",
    "            decoder_output, decoer_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden_state, encoder_outputs)\n",
    "\n",
    "            # Update input for next step (using output at this step)\n",
    "            log_likelihood, top_word = decoder_output.topk(1) \n",
    "            decoder_input = top_word.squeeze().detach()\n",
    "            decoder_word_output = target_vocab.index2word[decoder_input.item()]\n",
    "            decoder_word_outputs.append(decoder_word_output)\n",
    "            if decoder_word_output == '<EOS>':\n",
    "                break\n",
    "                \n",
    "\n",
    "        print(\"Input: \", \" \".join(tensor2sentence(input_tensor, input_vocab)))\n",
    "        print(\"Target: \", \" \".join(tensor2sentence(target_tensor, target_vocab)))\n",
    "        print(\"Result: \", \" \".join(decoder_word_outputs))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(input_vocab.n_words, 100)\n",
    "decoder = DecoderRNNAttention(target_vocab.n_words, 100, .1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_optimizer = torch.optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iteratively(encoder, decoder, tensor_pairs, encoder_optimizer, \n",
    "                    decoder_optimizer, criterion, max_length, validation_pairs,\n",
    "                    teacher_forcing_ratio = 1.0, epochs = 2):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch %d / %d\" % (epoch + 1, epochs))\n",
    "        loss = 0\n",
    "        for input_tensor, target_tensor in tqdm(tensor_pairs):\n",
    "            \n",
    "            loss += train_model(encoder, decoder, input_tensor, target_tensor, encoder_optimizer, \n",
    "                         decoder_optimizer, criterion, max_length, teacher_forcing_ratio)\n",
    "        \n",
    "        \n",
    "        # Print some statistics every epoch\n",
    "        epoch_loss = loss / len(tensor_pairs)\n",
    "        print('Loss: {:.4f}'.format(epoch_loss))\n",
    "        \n",
    "        # Print some examples after each epoch\n",
    "        # TODO: Don't just print the first 10 sentences of the validation set...\n",
    "        for input_tensor, target_tensor in validation_pairs[:10]:\n",
    "            evaluate_model(encoder, decoder, input_tensor, target_tensor, max_length)\n",
    "            print(\"\")\n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, tensor_pairs,  max_length):\n",
    "    \n",
    "\n",
    "    for input_tensor, target_tensor in tensor_pairs:\n",
    "        evaluate_model(encoder, decoder, input_tensor, target_tensor, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_sentences = zip(input_train, target_train)\n",
    "validation_sentences = zip(input_val, target_val)\n",
    "\n",
    "training_tensors = [pair2tensor(sent_pair) for sent_pair in training_sentences]\n",
    "validation_tensors = [pair2tensor(sent_pair) for sent_pair in validation_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My training setup could definitely be improved, but I can't spend to mucg time per coding session writing boilerplate. \n",
    "I'll improve it iteratively over coming projects!\n",
    "\n",
    "Let's launch training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8000/8000 [21:10<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.8954\n",
      "Input:  he behaved like a child . <EOS>\n",
      "Target:  han betedde sig som ett barn . <EOS>\n",
      "Result:  han har en gång . <EOS>\n",
      "\n",
      "Input:  `` trust me , '' he said . <EOS>\n",
      "Target:  ” lita på mig ” , sade han . <EOS>\n",
      "Result:  att jag är inte att jag tycker . <EOS>\n",
      "\n",
      "Input:  i can smell smoke . <EOS>\n",
      "Target:  det luktar rök . <EOS>\n",
      "Result:  jag kan jag kan inte\n",
      "\n",
      "Input:  the noise will wake the baby up . <EOS>\n",
      "Target:  ljudet kommer att väcka bebisen . <EOS>\n",
      "Result:  den är väldigt . <EOS>\n",
      "\n",
      "Input:  tom ca n't sing a high a . <EOS>\n",
      "Target:  tom kan inte sjunga höga a . <EOS>\n",
      "Result:  tom har inte . <EOS>\n",
      "\n",
      "Input:  who gave it to me ? <EOS>\n",
      "Target:  vem gav den till mig ? <EOS>\n",
      "Result:  vem ? <EOS>\n",
      "\n",
      "Input:  it was actually my fault . <EOS>\n",
      "Target:  det var faktiskt mitt fel . <EOS>\n",
      "Result:  det var min penna . <EOS>\n",
      "\n",
      "Input:  tom ran over someone 's dog . <EOS>\n",
      "Target:  tom körde över någons hund . <EOS>\n",
      "Result:  tom är glad . <EOS>\n",
      "\n",
      "Input:  i thanked tom for his help . <EOS>\n",
      "Target:  jag tackade tom för hans hjälp . <EOS>\n",
      "Result:  jag såg tom . <EOS>\n",
      "\n",
      "Input:  i 'm going to miss you , tom . <EOS>\n",
      "Target:  jag kommer att sakna dig , tom . <EOS>\n",
      "Result:  jag är du att du att göra att jag\n",
      "\n",
      "\n",
      "Epoch 2 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8000/8000 [25:26<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.0453\n",
      "Input:  he behaved like a child . <EOS>\n",
      "Target:  han betedde sig som ett barn . <EOS>\n",
      "Result:  han vill ha en gång . <EOS>\n",
      "\n",
      "Input:  `` trust me , '' he said . <EOS>\n",
      "Target:  ” lita på mig ” , sade han . <EOS>\n",
      "Result:  vi ses mig . <EOS>\n",
      "\n",
      "Input:  i can smell smoke . <EOS>\n",
      "Target:  det luktar rök . <EOS>\n",
      "Result:  jag kan ta . <EOS>\n",
      "\n",
      "Input:  the noise will wake the baby up . <EOS>\n",
      "Target:  ljudet kommer att väcka bebisen . <EOS>\n",
      "Result:  den . <EOS>\n",
      "\n",
      "Input:  tom ca n't sing a high a . <EOS>\n",
      "Target:  tom kan inte sjunga höga a . <EOS>\n",
      "Result:  tom har inte ha inte . <EOS>\n",
      "\n",
      "Input:  who gave it to me ? <EOS>\n",
      "Target:  vem gav den till mig ? <EOS>\n",
      "Result:  vem det ? <EOS>\n",
      "\n",
      "Input:  it was actually my fault . <EOS>\n",
      "Target:  det var faktiskt mitt fel . <EOS>\n",
      "Result:  det var min jacka min jacka .\n",
      "\n",
      "Input:  tom ran over someone 's dog . <EOS>\n",
      "Target:  tom körde över någons hund . <EOS>\n",
      "Result:  tom är väldigt väldigt väldigt väldigt väldigt\n",
      "\n",
      "Input:  i thanked tom for his help . <EOS>\n",
      "Target:  jag tackade tom för hans hjälp . <EOS>\n",
      "Result:  jag såg tom . <EOS>\n",
      "\n",
      "Input:  i 'm going to miss you , tom . <EOS>\n",
      "Target:  jag kommer att sakna dig , tom . <EOS>\n",
      "Result:  jag är tom . <EOS>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_iteratively(encoder, decoder, training_tensors, encoder_optimizer, decoder_optimizer, criterion, 11, validation_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8000/8000 [25:06<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6477\n",
      "Input:  he behaved like a child . <EOS>\n",
      "Target:  han betedde sig som ett barn . <EOS>\n",
      "Result:  han köpte du vill ha en penna .\n",
      "\n",
      "Input:  `` trust me , '' he said . <EOS>\n",
      "Target:  ” lita på mig ” , sade han . <EOS>\n",
      "Result:  vi ses på honom . <EOS>\n",
      "\n",
      "Input:  i can smell smoke . <EOS>\n",
      "Target:  det luktar rök . <EOS>\n",
      "Result:  jag kan vara . <EOS>\n",
      "\n",
      "Input:  the noise will wake the baby up . <EOS>\n",
      "Target:  ljudet kommer att väcka bebisen . <EOS>\n",
      "Result:  den här . <EOS>\n",
      "\n",
      "Input:  tom ca n't sing a high a . <EOS>\n",
      "Target:  tom kan inte sjunga höga a . <EOS>\n",
      "Result:  tom har inte en penna . <EOS>\n",
      "\n",
      "Input:  who gave it to me ? <EOS>\n",
      "Target:  vem gav den till mig ? <EOS>\n",
      "Result:  vem vill det ? <EOS>\n",
      "\n",
      "Input:  it was actually my fault . <EOS>\n",
      "Target:  det var faktiskt mitt fel . <EOS>\n",
      "Result:  det var inte att jag var min\n",
      "\n",
      "Input:  tom ran over someone 's dog . <EOS>\n",
      "Target:  tom körde över någons hund . <EOS>\n",
      "Result:  tom är det är det är det\n",
      "\n",
      "Input:  i thanked tom for his help . <EOS>\n",
      "Target:  jag tackade tom för hans hjälp . <EOS>\n",
      "Result:  jag tycker om att tom . <EOS>\n",
      "\n",
      "Input:  i 'm going to miss you , tom . <EOS>\n",
      "Target:  jag kommer att sakna dig , tom . <EOS>\n",
      "Result:  jag är bäst att sakna dig . <EOS>\n",
      "\n",
      "\n",
      "Epoch 2 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8000/8000 [25:07<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3354\n",
      "Input:  he behaved like a child . <EOS>\n",
      "Target:  han betedde sig som ett barn . <EOS>\n",
      "Result:  han brukar . <EOS>\n",
      "\n",
      "Input:  `` trust me , '' he said . <EOS>\n",
      "Target:  ” lita på mig ” , sade han . <EOS>\n",
      "Result:  vi ses mig . <EOS>\n",
      "\n",
      "Input:  i can smell smoke . <EOS>\n",
      "Target:  det luktar rök . <EOS>\n",
      "Result:  jag kan studera . <EOS>\n",
      "\n",
      "Input:  the noise will wake the baby up . <EOS>\n",
      "Target:  ljudet kommer att väcka bebisen . <EOS>\n",
      "Result:  den står på . <EOS>\n",
      "\n",
      "Input:  tom ca n't sing a high a . <EOS>\n",
      "Target:  tom kan inte sjunga höga a . <EOS>\n",
      "Result:  tom kan inte haft en sköldpadda . <EOS>\n",
      "\n",
      "Input:  who gave it to me ? <EOS>\n",
      "Target:  vem gav den till mig ? <EOS>\n",
      "Result:  vem ska jag gav det ? <EOS>\n",
      "\n",
      "Input:  it was actually my fault . <EOS>\n",
      "Target:  det var faktiskt mitt fel . <EOS>\n",
      "Result:  det var min lägenhet var min lägenhet\n",
      "\n",
      "Input:  tom ran over someone 's dog . <EOS>\n",
      "Target:  tom körde över någons hund . <EOS>\n",
      "Result:  tom är det här . <EOS>\n",
      "\n",
      "Input:  i thanked tom for his help . <EOS>\n",
      "Target:  jag tackade tom för hans hjälp . <EOS>\n",
      "Result:  jag såg att tom . <EOS>\n",
      "\n",
      "Input:  i 'm going to miss you , tom . <EOS>\n",
      "Target:  jag kommer att sakna dig , tom . <EOS>\n",
      "Result:  jag är dig . <EOS>\n",
      "\n",
      "\n",
      "Epoch 3 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8000/8000 [25:07<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.0872\n",
      "Input:  he behaved like a child . <EOS>\n",
      "Target:  han betedde sig som ett barn . <EOS>\n",
      "Result:  han brukar vilja ett öga . <EOS>\n",
      "\n",
      "Input:  `` trust me , '' he said . <EOS>\n",
      "Target:  ” lita på mig ” , sade han . <EOS>\n",
      "Result:  vi ses att vi ses på honom . <EOS>\n",
      "\n",
      "Input:  i can smell smoke . <EOS>\n",
      "Target:  det luktar rök . <EOS>\n",
      "Result:  jag kan ta med .\n",
      "\n",
      "Input:  the noise will wake the baby up . <EOS>\n",
      "Target:  ljudet kommer att väcka bebisen . <EOS>\n",
      "Result:  den här boken . <EOS>\n",
      "\n",
      "Input:  tom ca n't sing a high a . <EOS>\n",
      "Target:  tom kan inte sjunga höga a . <EOS>\n",
      "Result:  tom har inte haft en penna . <EOS>\n",
      "\n",
      "Input:  who gave it to me ? <EOS>\n",
      "Target:  vem gav den till mig ? <EOS>\n",
      "Result:  vem ska jag gav den ? <EOS>\n",
      "\n",
      "Input:  it was actually my fault . <EOS>\n",
      "Target:  det var faktiskt mitt fel . <EOS>\n",
      "Result:  det var min lägenhet var min familj\n",
      "\n",
      "Input:  tom ran over someone 's dog . <EOS>\n",
      "Target:  tom körde över någons hund . <EOS>\n",
      "Result:  tom är din dotter . <EOS>\n",
      "\n",
      "Input:  i thanked tom for his help . <EOS>\n",
      "Target:  jag tackade tom för hans hjälp . <EOS>\n",
      "Result:  jag träffade tom . <EOS>\n",
      "\n",
      "Input:  i 'm going to miss you , tom . <EOS>\n",
      "Target:  jag kommer att sakna dig , tom . <EOS>\n",
      "Result:  jag ska köra , du att köra , du\n",
      "\n",
      "\n",
      "Epoch 4 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8000/8000 [25:08<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.8795\n",
      "Input:  he behaved like a child . <EOS>\n",
      "Target:  han betedde sig som ett barn . <EOS>\n",
      "Result:  han stängde på det . <EOS>\n",
      "\n",
      "Input:  `` trust me , '' he said . <EOS>\n",
      "Target:  ” lita på mig ” , sade han . <EOS>\n",
      "Result:  vi ses på honom . <EOS>\n",
      "\n",
      "Input:  i can smell smoke . <EOS>\n",
      "Target:  det luktar rök . <EOS>\n",
      "Result:  jag kan olycka . <EOS>\n",
      "\n",
      "Input:  the noise will wake the baby up . <EOS>\n",
      "Target:  ljudet kommer att väcka bebisen . <EOS>\n",
      "Result:  den här boken . <EOS>\n",
      "\n",
      "Input:  tom ca n't sing a high a . <EOS>\n",
      "Target:  tom kan inte sjunga höga a . <EOS>\n",
      "Result:  tom har inte en tonårig aldrig äpple .\n",
      "\n",
      "Input:  who gave it to me ? <EOS>\n",
      "Target:  vem gav den till mig ? <EOS>\n",
      "Result:  vem bör den ? <EOS>\n",
      "\n",
      "Input:  it was actually my fault . <EOS>\n",
      "Target:  det var faktiskt mitt fel . <EOS>\n",
      "Result:  det var inte mina mina mina mina\n",
      "\n",
      "Input:  tom ran over someone 's dog . <EOS>\n",
      "Target:  tom körde över någons hund . <EOS>\n",
      "Result:  tom är snäll och gör det här\n",
      "\n",
      "Input:  i thanked tom for his help . <EOS>\n",
      "Target:  jag tackade tom för hans hjälp . <EOS>\n",
      "Result:  jag gjorde tom . <EOS>\n",
      "\n",
      "Input:  i 'm going to miss you , tom . <EOS>\n",
      "Target:  jag kommer att sakna dig , tom . <EOS>\n",
      "Result:  jag är glad att sakna dig . <EOS>\n",
      "\n",
      "\n",
      "Epoch 5 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8000/8000 [25:01<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7069\n",
      "Input:  he behaved like a child . <EOS>\n",
      "Target:  han betedde sig som ett barn . <EOS>\n",
      "Result:  han brukar . <EOS>\n",
      "\n",
      "Input:  `` trust me , '' he said . <EOS>\n",
      "Target:  ” lita på mig ” , sade han . <EOS>\n",
      "Result:  hurdan . <EOS>\n",
      "\n",
      "Input:  i can smell smoke . <EOS>\n",
      "Target:  det luktar rök . <EOS>\n",
      "Result:  jag kan greta . <EOS>\n",
      "\n",
      "Input:  the noise will wake the baby up . <EOS>\n",
      "Target:  ljudet kommer att väcka bebisen . <EOS>\n",
      "Result:  den kommer att behöva lite imorgon .\n",
      "\n",
      "Input:  tom ca n't sing a high a . <EOS>\n",
      "Target:  tom kan inte sjunga höga a . <EOS>\n",
      "Result:  tom en tonårig . <EOS>\n",
      "\n",
      "Input:  who gave it to me ? <EOS>\n",
      "Target:  vem gav den till mig ? <EOS>\n",
      "Result:  vem jag gav det ? <EOS>\n",
      "\n",
      "Input:  it was actually my fault . <EOS>\n",
      "Target:  det var faktiskt mitt fel . <EOS>\n",
      "Result:  det var inte mina mina mina mina\n",
      "\n",
      "Input:  tom ran over someone 's dog . <EOS>\n",
      "Target:  tom körde över någons hund . <EOS>\n",
      "Result:  tom är ditt namn . <EOS>\n",
      "\n",
      "Input:  i thanked tom for his help . <EOS>\n",
      "Target:  jag tackade tom för hans hjälp . <EOS>\n",
      "Result:  jag träffade tom . <EOS>\n",
      "\n",
      "Input:  i 'm going to miss you , tom . <EOS>\n",
      "Target:  jag kommer att sakna dig , tom . <EOS>\n",
      "Result:  jag är bäst att sakna dig , du måste\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_iteratively(encoder, decoder, training_tensors, encoder_optimizer, decoder_optimizer, criterion, 11, validation_tensors, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'pytorch_models/encoder.pt')\n",
    "torch.save(decoder.state_dict(), 'pytorch_models/decoder.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After almost 3 hours of training the model does not really perform that well, but more training would probably help. It doesn't feel that good to always stop training at a stage where the model does not perform well, but at this stage of exploration I don't want to run models for many hours before getting any results.\n",
    "\n",
    "The PyTorch tutorial limited their translation task to sentences with similar structure. This makes the task less interesting, but perhaps such a task can be solved in a more reasonable time frame?\n",
    "\n",
    "Let's try the same approach!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
